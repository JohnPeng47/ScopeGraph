{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scope_graph.chunk_resolution.chunk_graph import ChunkGraph\n",
    "from test_llama_ingest import ingest\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "with open(\"graph.json\", \"r\") as f:\n",
    "    cg = json.load(f)\n",
    "\n",
    "repo_path = \"tests/repos/cowboy-server\"\n",
    "chunk_graph = ChunkGraph.from_json(Path(repo_path), cg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 23, 1: 22, 2: 21, 3: 20, 4: 10, 5: 7, 6: 5, 7: 3, 8: 3, 9: 3, 10: 2, 11: 1, 12: 1, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 64: 1, 65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1, 76: 1, 77: 1, 78: 1, 79: 1, 80: 1, 81: 1, 82: 1, 83: 1, 84: 1, 85: 1, 86: 1, 87: 1, 88: 1, 89: 1, 90: 1, 91: 1, 92: 1, 93: 1, 94: 1, 95: 1, 96: 1, 97: 1, 98: 1, 99: 1, 100: 1, 101: 1, 102: 1, 103: 1, 104: 1, 105: 1, 106: 1, 107: 1, 108: 1, 109: 1, 110: 1, 111: 1, 112: 1, 113: 1, 114: 1, 115: 1, 116: 1, 117: 1, 118: 1, 119: 1, 120: 1, 121: 1, 122: 1, 123: 1, 124: 1, 125: 1, 126: 1, 127: 1, 128: 1, 129: 1, 130: 1, 131: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "node2cluster, cluster2node = chunk_graph.cluster()\n",
    "counter = Counter(node2cluster.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0\n",
      "  cowboy-server/main.py#85.13\n",
      "----------------------------------------------------------------------\n",
      "class LogfireLogUser(BaseHTTPMiddleware):\n",
      "    async def dispatch(self, request: Request, call_next):\n",
      "        try:\n",
      "            # we have to skip requests with x-task-auth or else logfire will log an exception for this\n",
      "            # request when it tries to acces request.state.db\n",
      "            if not request.headers.get(\"x-task-auth\", None):\n",
      "                with logfire.span(\"request\"):\n",
      "                    user = get_current_user(request)\n",
      "                    logfire.info(\"{user}\", user=user.email)\n",
      "        except AttributeError as e:\n",
      "            pass\n",
      "        finally:\n",
      "            response = await call_next(request)\n",
      "            return response\n",
      "  auth/permissions.py#93.50\n",
      "----------------------------------------------------------------------\n",
      "from starlette.requests import Request\n",
      "\n",
      "import logging\n",
      "from abc import ABC, abstractmethod\n",
      "\n",
      "from fastapi import HTTPException\n",
      "from starlette.requests import Request\n",
      "from starlette.status import HTTP_403_FORBIDDEN, HTTP_404_NOT_FOUND\n",
      "\n",
      "from .service import get_current_user\n",
      "\n",
      "\n",
      "class BasePermission(ABC):\n",
      "    \"\"\"\n",
      "    Abstract permission that all other Permissions must be inherited from.\n",
      "\n",
      "    Defines basic error message, status & error codes.\n",
      "\n",
      "    Upon initialization, calls abstract method  `has_required_permissions`\n",
      "    which will be specific to concrete implementation of Permission class.\n",
      "\n",
      "    You would write your permissions like this:\n",
      "\n",
      "    .. code-block:: python\n",
      "\n",
      "        class TeapotUserAgentPermission(BasePermission):\n",
      "\n",
      "            def has_required_permissions(self, request: Request) -> bool:\n",
      "                return request.headers.get('User-Agent') == \"Teapot v1.0\"\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    user_error_msg = [{\"msg\": \"User not found\"}]\n",
      "    user_error_code = HTTP_404_NOT_FOUND\n",
      "\n",
      "    role = None\n",
      "\n",
      "    # @abstractmethod\n",
      "    # def has_required_permissions(self, request: Request) -> bool: ...\n",
      "\n",
      "    def __init__(self, request: Request):\n",
      "        user = get_current_user(request=request)\n",
      "        if not user:\n",
      "            raise HTTPException(\n",
      "                status_code=self.user_error_code, detail=self.user_error_msg\n",
      "            )\n",
      "\n",
      "        # if not self.has_required_permissions(request):\n",
      "        #     raise HTTPException(\n",
      "        #         status_code=self.user_role_error_code, detail=self.user_role_error_msg\n",
      "        #     )\n",
      "#     \"\"\"\n",
      "  auth/service.py#99.54\n",
      "----------------------------------------------------------------------\n",
      "# def get_current_user(request: Request) -> CowboyUser:\n",
      "#     user_email = extract_user_email_jwt(request=request)\n",
      "\n",
      "#     if not user_email:\n",
      "#         log.exception(f\"Failed to extract user email\")\n",
      "#         raise InvalidCredentialException\n",
      "\n",
      "#     # kinda of strange ... if user exists, we generate a random password\n",
      "#     # for the user here ...\n",
      "#     return get_or_create(\n",
      "#         db_session=request.state.db,\n",
      "#         user_in=UserRegister(email=user_email),\n",
      "#     )\n",
      "\n",
      "\n",
      "def get_current_user(request: Request) -> CowboyUser:\n",
      "    user_email = extract_user_email_jwt(request=request)\n",
      "\n",
      "    if not user_email:\n",
      "        log.exception(f\"Failed to extract user email\")\n",
      "        raise InvalidCredentialException\n",
      "\n",
      "    # kinda of strange ... if user exists, we generate a random password\n",
      "    # for the user here ...\n",
      "    try:\n",
      "        user = get_by_email(\n",
      "            db_session=get_db(request),\n",
      "            email=user_email,\n",
      "        )\n",
      "    # this is special case for requests polling the /task/get endpoint\n",
      "    # where we are not passed a db session, and we want to proceed with the rest\n",
      "    # of endpoint logic\n",
      "    except DBNotSetException:\n",
      "        print(\"No db set\")\n",
      "        return None\n",
      "\n",
      "    # generic case for user not existing\n",
      "    if not user:\n",
      "        print(\"No user\")\n",
      "        raise HTTPException(\n",
      "            status_code=HTTP_401_UNAUTHORIZED, detail=[{\"msg\": \"User not found\"}]\n",
      "        )\n",
      "\n",
      "    return user\n",
      "\n",
      "\n",
      "def store_oai_key(api_key, user_id):\n",
      "    sm = SecretManager()\n",
      "    sm.store_parameter(\"OAI_KEY_\" + str(user_id), api_key)\n",
      "\n",
      "\n",
      "def retrieve_oai_key(user_id):\n",
      "    sm = SecretManager()\n",
      "    return sm.retrieve_parameter(\"OAI_KEY_\" + str(user_id))\n",
      "  auth/views.py#104.16\n",
      "----------------------------------------------------------------------\n",
      "@auth_router.post(\"/user/register\", response_model=UserLoginResponse)\n",
      "def register_user(\n",
      "    user_in: UserRegister,\n",
      "    db_session: Session = Depends(get_db),\n",
      "):\n",
      "    user = get_by_email(db_session=db_session, email=user_in.email)\n",
      "    if user:\n",
      "        raise HTTPException(\n",
      "            status_code=status.HTTP_400_BAD_REQUEST,\n",
      "            detail=\"A user with this email already exists.\",\n",
      "        )\n",
      "\n",
      "    user = create(db_session=db_session, user_in=user_in)\n",
      "\n",
      "    logfire.info(\"User registered\", user=user.email)\n",
      "\n",
      "    return user\n",
      "  database/core.py#119.52\n",
      "----------------------------------------------------------------------\n",
      "class CustomBase:\n",
      "\n",
      "    @property\n",
      "    def _repr_attrs_str(self):\n",
      "        max_length = self.__repr_max_length__\n",
      "\n",
      "        values = []\n",
      "        single = len(self.__repr_attrs__) == 1\n",
      "        for key in self.__repr_attrs__:\n",
      "            if not hasattr(self, key):\n",
      "                raise KeyError(\n",
      "                    \"{} has incorrect attribute '{}' in \"\n",
      "                    \"__repr__attrs__\".format(self.__class__, key)\n",
      "                )\n",
      "            value = getattr(self, key)\n",
      "            wrap_in_quote = isinstance(value, str)\n",
      "\n",
      "            value = str(value)\n",
      "            if len(value) > max_length:\n",
      "                value = value[:max_length] + \"...\"\n",
      "\n",
      "            if wrap_in_quote:\n",
      "                value = \"'{}'\".format(value)\n",
      "            values.append(value if single else \"{}:{}\".format(key, value))\n",
      "\n",
      "        return \" \".join(values)\n",
      "\n",
      "    def __repr__(self):\n",
      "        # get id like '#123'\n",
      "        id_str = (\"#\" + self._id_str) if self._id_str else \"\"\n",
      "        # join class name, id and repr_attrs\n",
      "        return \"<{} {}{}>\".format(\n",
      "            self.__class__.__name__,\n",
      "            id_str,\n",
      "            \" \" + self._repr_attrs_str if self._repr_attrs_str else \"\",\n",
      "        )\n",
      "\n",
      "\n",
      "Base = declarative_base(cls=CustomBase)\n",
      "\n",
      "\n",
      "class DBNotSetException(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "def get_db(request: Request):\n",
      "    try:\n",
      "        return request.state.db\n",
      "    except AttributeError:\n",
      "        raise DBNotSetException(\"Database not set on request.\")\n",
      "\n",
      "\n",
      "# Triggers initial response field validation error\n",
      "# DbSession = Annotated[Session, Depends(get_db)]\n",
      "  experiments/views.py#130.34\n",
      "----------------------------------------------------------------------\n",
      "from src.database.core import get_db\n",
      "from src.auth.service import get_current_user, CowboyUser\n",
      "from src.repo.service import get_experiment\n",
      "from src.test_modules.service import get_tms_by_names\n",
      "\n",
      "from .models import ExperimentRequest\n",
      "from .augment_test import run_experiment\n",
      "\n",
      "from fastapi import APIRouter, Depends\n",
      "from sqlalchemy.orm import Session\n",
      "\n",
      "\n",
      "exp_router = APIRouter()\n",
      "\n",
      "\n",
      "@exp_router.post(\"/experiment/create\")\n",
      "def create_experiment(\n",
      "    exp_config: ExperimentRequest,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "    repo = get_experiment(\n",
      "        db_session=db_session, curr_user=current_user, repo_name=exp_config.repo_name\n",
      "    )\n",
      "    tm_models = get_tms_by_names(\n",
      "        db_session=db_session, repo_id=repo.id, tm_names=exp_config.tms\n",
      "    )\n",
      "\n",
      "    run_experiment(\n",
      "        repo=repo,\n",
      "        test_modules=tm_models,\n",
      "        to_keep=int(exp_config.to_keep),\n",
      "        to_delete=int(exp_config.to_delete),\n",
      "    )\n",
      "  queue/permissions.py#139.21\n",
      "----------------------------------------------------------------------\n",
      "from src.auth.permissions import BasePermission\n",
      "from src.auth.service import get_current_user\n",
      "\n",
      "from fastapi import HTTPException\n",
      "\n",
      "from starlette.requests import Request\n",
      "from starlette.responses import Response\n",
      "\n",
      "\n",
      "class TaskGetPermissions(BasePermission):\n",
      "    def __init__(self, request: Request):\n",
      "        try:\n",
      "            user = get_current_user(request=request)\n",
      "            if not user:\n",
      "                raise HTTPException(\n",
      "                    status_code=self.user_error_code, detail=self.user_error_msg\n",
      "                )\n",
      "\n",
      "        # this happens when the db is not set\n",
      "        except AttributeError:\n",
      "            pass\n",
      "  queue/views.py#141.23\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.api.runner.shared import Task\n",
      "\n",
      "from .service import list_tasks, dequeue_task, complete_task\n",
      "from .models import CompleteTaskRequest\n",
      "from .core import TaskQueue, get_queue, get_token_registry, get_token\n",
      "\n",
      "from fastapi import APIRouter, Depends, HTTPException, Response\n",
      "\n",
      "from src.database.core import get_db\n",
      "from src.auth.service import get_current_user\n",
      "from src.auth.models import CowboyUser\n",
      "\n",
      "from typing import List, Set\n",
      "\n",
      "task_queue_router = APIRouter()\n",
      "\n",
      "\n",
      "@task_queue_router.get(\"/task/list\", response_model=List[Task])\n",
      "def list(\n",
      "    task_queue: TaskQueue = Depends(get_queue),\n",
      "    curr_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "    tasks = list_tasks(task_queue=task_queue, user_id=curr_user.id, n=3)\n",
      "    return tasks\n",
      "  queue/views.py#142.53\n",
      "----------------------------------------------------------------------\n",
      "# incredibly hacky, basically, to prevent db connections from being used up\n",
      "# we exclude db connections for this endpoint, we do the following:\n",
      "# 1. First request actually does get a db sess, which we use to auth the user\n",
      "# 2. Grab user id and add it into a in-mem token_registry list\n",
      "# 3. Return user id as \"set-x-task-auth\" header\n",
      "# 4. When the client puts user id into x-task-auth header\n",
      "# 5. Our DBMiddleware will check the header, and if token is in registry, will not\n",
      "# add a db session to the request\n",
      "@task_queue_router.get(\"/task/get\", response_model=List[Task])\n",
      "def get(\n",
      "    response: Response,\n",
      "    task_queue: TaskQueue = Depends(get_queue),\n",
      "    # don't try to do anything with curr_user because most of the time\n",
      "    # we only have user_token to work with\n",
      "    curr_user: CowboyUser = Depends(get_current_user),\n",
      "    token_registry: Set[str] = Depends(get_token_registry),\n",
      "    user_token: str = Depends(get_token),\n",
      "    # perms: str = Depends(PermissionsDependency([TaskGetPermissions])),\n",
      "):\n",
      "    # at this point we have passed db user auth; test\n",
      "    # catches if user sets random token\n",
      "    if user_token and user_token not in token_registry:\n",
      "        raise HTTPException(\n",
      "            status_code=401,\n",
      "            detail=\"Token not in registry, cannot proceed. \\\n",
      "            Are you sure you are logged in on the client?\",\n",
      "        )\n",
      "    # issue token if it does not exist\n",
      "    elif not user_token:\n",
      "        print(\"Setting new token ..\")\n",
      "        response.headers[\"set-x-task-auth\"] = str(curr_user.id)\n",
      "        token_registry.add(str(curr_user.id))\n",
      "\n",
      "    tasks = dequeue_task(\n",
      "        task_queue=task_queue, user_id=curr_user.id if curr_user else int(user_token)\n",
      "    )\n",
      "    return tasks\n",
      "\n",
      "\n",
      "@task_queue_router.post(\"/task/complete\", response_model=CompleteTaskRequest)\n",
      "def complete(\n",
      "    task: CompleteTaskRequest,\n",
      "    task_queue: TaskQueue = Depends(get_queue),\n",
      "    curr_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "\n",
      "    task_queue = complete_task(\n",
      "        task_queue=task_queue,\n",
      "        user_id=curr_user.id,\n",
      "        task_id=task.task_id,\n",
      "        result=task.result,\n",
      "    )\n",
      "    return task\n",
      "  repo/service.py#146.15\n",
      "----------------------------------------------------------------------\n",
      "def get_or_raise(*, db_session, curr_user: CowboyUser, repo_name: str) -> RepoConfig:\n",
      "    \"\"\"Returns a repo based on the given repo name.\"\"\"\n",
      "    repo = (\n",
      "        db_session.query(RepoConfig)\n",
      "        .filter(\n",
      "            RepoConfig.repo_name == repo_name,\n",
      "            RepoConfig.user_id == curr_user.id,\n",
      "        )\n",
      "        .one_or_none()\n",
      "    )\n",
      "    # TODO: consider raising pydantic Validation error here instead\n",
      "    # seems to be what dispatch does\n",
      "    if not repo:\n",
      "        raise HTTPException(status_code=400, detail=f\"Repo {repo_name} not found\")\n",
      "\n",
      "    return repo\n",
      "  repo/views.py#152.22\n",
      "----------------------------------------------------------------------\n",
      "@repo_router.post(\"/repo/create\", response_model=RepoConfigCreate)\n",
      "async def create_repo(\n",
      "    repo_in: RepoConfigCreate,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "    task_queue: TaskQueue = Depends(get_queue),\n",
      "):\n",
      "    repo = get(\n",
      "        db_session=db_session, repo_name=repo_in.repo_name, curr_user=current_user\n",
      "    )\n",
      "    if repo:\n",
      "        raise HTTPException(\n",
      "            status_code=400, detail=\"A repo with this name already exists.\"\n",
      "        )\n",
      "\n",
      "    repo_config = await create_or_update(\n",
      "        db_session=db_session,\n",
      "        repo_in=repo_in,\n",
      "        curr_user=current_user,\n",
      "        task_queue=task_queue,\n",
      "    )\n",
      "    # need as_dict to convert cloned_folders to list\n",
      "    return repo_config.to_dict()\n",
      "  repo/views.py#154.12\n",
      "----------------------------------------------------------------------\n",
      "@repo_router.delete(\"/repo/clean/{repo_name}\", response_model=HTTPSuccess)\n",
      "def clean_repo(\n",
      "    repo_name: str,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "    cleaned = clean(db_session=db_session, repo_name=repo_name, curr_user=current_user)\n",
      "\n",
      "    if not cleaned:\n",
      "        raise HTTPException(\n",
      "            status_code=400, detail=\"A repo with this name does not exists.\"\n",
      "        )\n",
      "    return HTTPSuccess()\n",
      "  repo/views.py#155.20\n",
      "----------------------------------------------------------------------\n",
      "@repo_router.get(\"/repo/get/{repo_name}\", response_model=RepoConfigGet)\n",
      "def get_repo(\n",
      "    repo_name: str,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "    repo = get(db_session=db_session, repo_name=repo_name, curr_user=current_user)\n",
      "    if not repo:\n",
      "        raise HTTPException(\n",
      "            status_code=400, detail=\"A repo with this name does not exists.\"\n",
      "        )\n",
      "    return repo.to_dict()\n",
      "\n",
      "\n",
      "@repo_router.get(\"/repo/list\", response_model=RepoConfigList)\n",
      "def list_repos(\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "    repos = list(db_session=db_session, curr_user=current_user)\n",
      "    return RepoConfigList(repo_list=repos)\n",
      "  repo/views.py#156.18\n",
      "----------------------------------------------------------------------\n",
      "# TODO: this should return HEAD of repo.source_folder rather than the remote repo\n",
      "# once we finish our task refactor\n",
      "@repo_router.get(\"/repo/get_head/{repo_name}\", response_model=RepoConfigRemoteCommit)\n",
      "def get_head(\n",
      "    repo_name: str,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "    repo = get(db_session=db_session, repo_name=repo_name, curr_user=current_user)\n",
      "    if not repo:\n",
      "        raise HTTPException(\n",
      "            status_code=400, detail=\"A repo with this name does not exists.\"\n",
      "        )\n",
      "\n",
      "    git_repo = GitRepo(Path(repo.source_folder))\n",
      "\n",
      "    # return RepoConfigRemoteCommit(sha=git_repo.local_commit)\n",
      "    return RepoConfigRemoteCommit(sha=git_repo.remote_commit)\n",
      "  target_code/views.py#173.36\n",
      "----------------------------------------------------------------------\n",
      "from fastapi import APIRouter, Depends, HTTPException\n",
      "from src.database.core import get_db\n",
      "from src.repo.service import get_or_raise\n",
      "from src.auth.service import get_current_user\n",
      "\n",
      "from src.test_modules.service import get_tm_by_name\n",
      "\n",
      "from .models import TgtCodeDeleteRequest\n",
      "from .service import delete_target_code\n",
      "\n",
      "\n",
      "tgtcode_router = APIRouter()\n",
      "\n",
      "\n",
      "@tgtcode_router.post(\"/tgt_code/delete/\")\n",
      "async def delete_tgt_code(\n",
      "    tgt_delete_req: TgtCodeDeleteRequest,\n",
      "    user=Depends(get_current_user),\n",
      "    db=Depends(get_db),\n",
      "):\n",
      "    \"\"\"\n",
      "    Delete all target code for a tesst module\n",
      "    \"\"\"\n",
      "    try:\n",
      "        repo = get_or_raise(\n",
      "            db_session=db, curr_user=user, repo_name=tgt_delete_req.repo_name\n",
      "        )\n",
      "        tm_model = get_tm_by_name(\n",
      "            db_session=db, repo_id=repo.id, tm_name=tgt_delete_req.tm_name\n",
      "        )\n",
      "        deleted = delete_target_code(db_session=db, tm_id=tm_model.id)\n",
      "\n",
      "    except Exception as e:\n",
      "        raise HTTPException(status_code=500, detail=str(e))\n",
      "\n",
      "    return {\"detail\": \"Target code deleted\"}\n",
      "  test_gen/service.py#222.19\n",
      "----------------------------------------------------------------------\n",
      "def select_tms(*, db_session, repo_id, request: TMSelectModeBase, src_repo: SourceRepo):\n",
      "    if request.mode == TMSelectMode.AUTO.value:\n",
      "        tm_models = get_all_tms_sorted(\n",
      "            db_session=db_session, src_repo=src_repo, repo_id=repo_id, n=AUTO_GEN_SIZE\n",
      "        )\n",
      "    elif request.mode == TMSelectMode.FILE.value:\n",
      "        tm_models = get_tms_by_filename(\n",
      "            db_session=db_session, repo_id=repo_id, src_file=request.files\n",
      "        )\n",
      "    elif request.mode == TMSelectMode.TM.value:\n",
      "        tm_models = get_tms_by_names(\n",
      "            db_session=db_session, repo_id=repo_id, tm_names=request.tms\n",
      "        )\n",
      "    elif request.mode == TMSelectMode.ALL.value:\n",
      "        tm_models = get_tms_by_names(\n",
      "            db_session=db_session, repo_id=repo_id, tm_names=[]\n",
      "        )\n",
      "\n",
      "    return tm_models\n",
      "  test_gen/views.py#225.46\n",
      "----------------------------------------------------------------------\n",
      "@test_gen_router.post(\"/test-gen/augment\")\n",
      "async def augment_test_route(\n",
      "    request: AugmentTestRequest,\n",
      "    db_session=Depends(get_db),\n",
      "    session_id=Depends(get_session_id),\n",
      "    curr_user=Depends(get_current_user),\n",
      "    task_queue=Depends(get_queue),\n",
      "):\n",
      "    \"\"\"\n",
      "    Augment tests for a test module\n",
      "    \"\"\"\n",
      "    repo = get_or_raise(\n",
      "        db_session=db_session, curr_user=curr_user, repo_name=request.repo_name\n",
      "    )\n",
      "    src_repo = SourceRepo(Path(repo.source_folder))\n",
      "    tm_models = select_tms(\n",
      "        db_session=db_session, repo_id=repo.id, request=request, src_repo=src_repo\n",
      "    )\n",
      "\n",
      "    if not tm_models:\n",
      "        detail = (\n",
      "            MODE_AUTO_ERROR_MSG\n",
      "            if request.mode == \"auto\"\n",
      "            else MODE_FILES_ERROR_MSG.format(filenames=request.files)\n",
      "        )\n",
      "        return HTTPException(status_code=400, detail=detail)\n",
      "\n",
      "    # TODO: put this into a service\n",
      "    coroutines = []\n",
      "    for tm_model in tm_models:\n",
      "        coroutine = augment_test(\n",
      "            db_session=db_session,\n",
      "            task_queue=task_queue,\n",
      "            repo=repo,\n",
      "            tm_model=tm_model,\n",
      "            curr_user=curr_user,\n",
      "            session_id=session_id,\n",
      "        )\n",
      "        coroutines.append(coroutine)\n",
      "\n",
      "    test_results = await asyncio.gather(*coroutines)\n",
      "    test_results = reduce(lambda x, y: x + y, test_results)\n",
      "\n",
      "    # we save here after async ops have finished running\n",
      "    save_all(db_session=db_session, test_results=test_results)\n",
      "\n",
      "    return AugmentTestResponse(session_id=session_id)\n",
      "  test_gen/views.py#226.16\n",
      "----------------------------------------------------------------------\n",
      "@test_gen_router.get(\"/test-gen/results/{session_id}\")\n",
      "def get_results(\n",
      "    session_id: str,\n",
      "    db_session: Session = Depends(get_db),\n",
      "):\n",
      "    trs = get_test_results_by_sessionid(db_session=db_session, session_id=session_id)\n",
      "    return [\n",
      "        TestResultResponse(\n",
      "            id=str(tr.id),\n",
      "            name=tr.name,\n",
      "            test_case=tr.test_case,\n",
      "            test_file=tr.testfile,\n",
      "            cov_improved=tr.coverage_improve(),\n",
      "            decided=tr.decide,\n",
      "        )\n",
      "        for tr in trs\n",
      "    ]\n",
      "  test_gen/views.py#227.58\n",
      "----------------------------------------------------------------------\n",
      "@test_gen_router.post(\"/test-gen/results/decide/{sesssion_id}\")\n",
      "def accept_user_decision(\n",
      "    request: UserDecisionRequest,\n",
      "    curr_user=Depends(get_current_user),\n",
      "    db_session=Depends(get_db),\n",
      "):\n",
      "    \"\"\"\n",
      "    Takes the result of the selected tests and appends all of the selected\n",
      "    tests to TestModule (testfile/test class). Then check out a new branch against\n",
      "    the remote repo with the changed files\n",
      "    \"\"\"\n",
      "\n",
      "    repo_id = get_test_result_by_id_or_raise(\n",
      "        db_session=db_session, test_id=request.user_decision[0].id\n",
      "    ).repo_id\n",
      "    repo = get_by_id_or_raise(\n",
      "        db_session=db_session, curr_user=curr_user, repo_id=repo_id\n",
      "    )\n",
      "    src_repo = SourceRepo(Path(repo.source_folder))\n",
      "    git_repo = GitRepo(Path(repo.source_folder))\n",
      "\n",
      "    # NOTE: LintExceptions at this step should not happen because they would have occurred\n",
      "    # earlier during the Evaluation phase\n",
      "    changed_files = set()\n",
      "    accepted_trs = []\n",
      "    for decision in request.user_decision:\n",
      "        tr = get_test_result_by_id_or_raise(db_session=db_session, test_id=decision.id)\n",
      "        test_file = src_repo.find_file(tr.testfile)\n",
      "        if decision.decision:\n",
      "            test_file.append(tr.test_case, class_name=tr.classname)\n",
      "            src_repo.write_file(test_file.path)\n",
      "            changed_files.add(str(test_file.path))\n",
      "            accepted_trs.append(tr)\n",
      "\n",
      "        update_test_result_decision(\n",
      "            db_session=db_session, test_id=decision.id, decision=decision.decision\n",
      "        )\n",
      "\n",
      "    # update stats\n",
      "    with update_repo_stats(db_session=db_session, repo=repo) as repo_stats:\n",
      "        repo_stats.accepted_tests += len(accepted_trs)\n",
      "        repo_stats.rejected_tests += len(request.user_decision) - len(accepted_trs)\n",
      "\n",
      "        # update logfire metrics\n",
      "        accepted_count = logfire.metric_counter(\"accepted_results\", unit=\"1\")\n",
      "        failed_count = logfire.metric_counter(\"failed_results\", unit=\"1\")\n",
      "        total_count = logfire.metric_counter(\"total_results\", unit=\"1\")\n",
      "\n",
      "        accepted_count.add(len(accepted_trs))\n",
      "        failed_count.add(len(request.user_decision) - len(accepted_trs))\n",
      "        total_count.add(len(request.user_decision))\n",
      "\n",
      "    msg = gen_commit_msg(accepted_trs)\n",
      "    compare_url = git_repo.checkout_and_push(\n",
      "        \"cowboy-augmented-tests\", msg, list(changed_files)\n",
      "    )\n",
      "\n",
      "    return UserDecisionResponse(compare_url=compare_url)\n",
      "  test_modules/service.py#233.27\n",
      "----------------------------------------------------------------------\n",
      "def get_tm_by_name(\n",
      "    *, db_session: Session, repo_id: str, tm_name: str\n",
      ") -> TestModuleModel:\n",
      "    \"\"\"\n",
      "    Query by name and return all if no names are provided\n",
      "    \"\"\"\n",
      "\n",
      "    query = db_session.query(TestModuleModel).filter(TestModuleModel.repo_id == repo_id)\n",
      "    if tm_name:\n",
      "        query = query.filter(TestModuleModel.name == tm_name)\n",
      "\n",
      "    return query.one_or_none()\n",
      "\n",
      "\n",
      "def get_tms_by_names(\n",
      "    *, db_session: Session, repo_id: str, tm_names: List[str]\n",
      ") -> List[TestModuleModel]:\n",
      "    \"\"\"\n",
      "    Query by name and return all if no names are provided\n",
      "    \"\"\"\n",
      "    if tm_names == []:\n",
      "        return get_all_tms(db_session=db_session, repo_id=repo_id)\n",
      "\n",
      "    query = db_session.query(TestModuleModel).filter(TestModuleModel.repo_id == repo_id)\n",
      "    if tm_names:\n",
      "        query = query.filter(TestModuleModel.name.in_(tm_names))\n",
      "\n",
      "    return query.all()\n",
      "  test_modules/service.py#235.17\n",
      "----------------------------------------------------------------------\n",
      "# TODO: need to figure out when to set this flag to False\n",
      "def get_all_tms_sorted(\n",
      "    *, db_session: Session, repo_id: str, src_repo: SourceRepo, n: int = 2\n",
      ") -> List[TestModuleModel]:\n",
      "    \"\"\"\n",
      "    Query all TMs for a repo\n",
      "    \"\"\"\n",
      "    all_tms = get_all_tms(db_session=db_session, repo_id=repo_id)\n",
      "    sorted_tms = sorted(all_tms, key=lambda tm: tm.agg_score(src_repo), reverse=True)\n",
      "    select_tms = sorted_tms[:n]\n",
      "\n",
      "    # update auto_gen flag on TMs\n",
      "    for tm in select_tms:\n",
      "        tm.auto_gen = True\n",
      "        update_tm(db_session=db_session, tm_model=tm)\n",
      "\n",
      "    return select_tms\n",
      "  test_modules/views.py#237.27\n",
      "----------------------------------------------------------------------\n",
      "@tm_router.post(\"/tm/build-mapping\")\n",
      "async def get_tm_target_coverage(\n",
      "    request: BuildMappingRequest,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "    task_queue: TaskQueue = Depends(get_queue),\n",
      "):\n",
      "    repo = get_or_raise(\n",
      "        db_session=db_session, curr_user=current_user, repo_name=request.repo_name\n",
      "    )\n",
      "    src_repo = SourceRepo(Path(repo.source_folder))\n",
      "    tm_models = select_tms(\n",
      "        db_session=db_session, repo_id=repo.id, request=request, src_repo=src_repo\n",
      "    )\n",
      "\n",
      "    try:\n",
      "        await create_tgt_coverage(\n",
      "            db_session=db_session,\n",
      "            task_queue=task_queue,\n",
      "            repo=repo,\n",
      "            tm_models=tm_models,\n",
      "            overwrite=request.overwrite,\n",
      "        )\n",
      "\n",
      "        return HTTPSuccess()\n",
      "\n",
      "    except ClientRunnerException as e:\n",
      "        raise e\n",
      "  test_modules/views.py#238.23\n",
      "----------------------------------------------------------------------\n",
      "@tm_router.get(\"/tm/{repo_name}\", response_model=List[TestModuleReponse])\n",
      "def get_tms(\n",
      "    repo_name: str,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "):\n",
      "    repo = get_or_raise(\n",
      "        db_session=db_session, curr_user=current_user, repo_name=repo_name\n",
      "    )\n",
      "    src_repo = SourceRepo(Path(repo.source_folder))\n",
      "    tms = [\n",
      "        tm.serialize(src_repo)\n",
      "        for tm in get_all_tms(db_session=db_session, repo_id=repo.id)\n",
      "    ]\n",
      "\n",
      "    return [\n",
      "        TestModuleReponse(\n",
      "            filepath=str(tm.path),\n",
      "            name=tm.name,\n",
      "            unit_tests=[ut.name for ut in tm.tests],\n",
      "        )\n",
      "        for tm in tms\n",
      "    ]\n",
      "Cluster 1\n",
      "  runner/shared.py#2.37\n",
      "----------------------------------------------------------------------\n",
      "class TaskResult(BaseModel):\n",
      "    coverage: Optional[Dict] = None\n",
      "    failed: Optional[Dict] = None\n",
      "    exception: Optional[str] = None\n",
      "\n",
      "    @model_validator(mode=\"before\")\n",
      "    def check_coverage_or_exception(cls, values):\n",
      "        coverage, failed, exception = (\n",
      "            values.get(\"coverage\"),\n",
      "            values.get(\"failed\"),\n",
      "            values.get(\"exception\"),\n",
      "        )\n",
      "        if exception and (coverage or failed):\n",
      "            raise ValueError(\n",
      "                \"If 'exception' is specified, 'coverage' and 'failed' must not be specified.\"\n",
      "            )\n",
      "        if not exception and not (coverage or failed):\n",
      "            raise ValueError(\n",
      "                \"Either 'coverage' and 'failed' or 'exception' must be specified.\"\n",
      "            )\n",
      "        return values\n",
      "\n",
      "\n",
      "class Task(BaseModel):\n",
      "    \"\"\"\n",
      "    Task datatype\n",
      "    \"\"\"\n",
      "\n",
      "    type: TaskType\n",
      "    task_id: str = Field(default_factory=lambda: generate_id())\n",
      "    result: Optional[TaskResult] = Field(default=None)\n",
      "    status: str = Field(default=TaskStatus.PENDING.value)\n",
      "    task_args: Optional[Any] = Field(default=None)\n",
      "\n",
      "\n",
      "class FunctionArg(BaseModel):\n",
      "    name: str\n",
      "    is_meth: bool\n",
      "  runner/shared.py#4.36\n",
      "----------------------------------------------------------------------\n",
      "class RunTestTaskArgs(BaseModel):\n",
      "\n",
      "    @classmethod\n",
      "    def from_json(\n",
      "        cls,\n",
      "        repo_name: str,\n",
      "        patch_file: Dict = {},\n",
      "        exclude_tests: List[Tuple[Dict, str]] = [],\n",
      "        include_tests: List[str] = [],\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Used by client\n",
      "        \"\"\"\n",
      "        partial = cls(\n",
      "            repo_name=repo_name,\n",
      "            patch_file=patch_file,\n",
      "            exclude_tests=exclude_tests,\n",
      "            include_tests=include_tests,\n",
      "        )\n",
      "\n",
      "        if partial.patch_file:\n",
      "            partial.patch_file = PatchFile(\n",
      "                path=Path(partial.patch_file[\"path\"]),\n",
      "                patch=partial.patch_file[\"patch\"],\n",
      "            )\n",
      "        if partial.exclude_tests:\n",
      "            partial.exclude_tests = [\n",
      "                (\n",
      "                    FunctionArg(\n",
      "                        name=func[0],\n",
      "                        is_meth=func[1],\n",
      "                    ),\n",
      "                    Path(path),\n",
      "                )\n",
      "                for func, path in partial.exclude_tests\n",
      "            ]\n",
      "\n",
      "        return partial\n",
      "  cowboy_lib/coverage.py#29.51\n",
      "----------------------------------------------------------------------\n",
      "class CoverageResult:\n",
      "    def _parse_failed_tests(\n",
      "        self, stdout: str\n",
      "    ) -> Tuple[List[Tuple[str, TestError]], int]:\n",
      "        \"\"\"\n",
      "        Parse every failed test from pytest output\n",
      "        \"\"\"\n",
      "        pattern = r\"FAILED\\s+(?:\\S+?)::(\\S+?)\\s+-\"\n",
      "        failed_modules = re.findall(pattern, stdout)\n",
      "\n",
      "        # NOTE: currently treating parameterized tests as single tests\n",
      "        total_failed = set()\n",
      "\n",
      "        # parse test_module names\n",
      "        for failed_test in failed_modules:\n",
      "            # logger.info(f\"Failed tests: {failed_test}\")\n",
      "\n",
      "            if \"[\" in failed_test:\n",
      "                failed_test = failed_test.split(\"[\")[0]\n",
      "\n",
      "            if \"::\" in failed_test:\n",
      "                test_module = failed_test.split(\"::\")[0]\n",
      "                failed_test = failed_test.split(\"::\")[1]\n",
      "                total_failed.add(f\"{test_module}.{failed_test}\")\n",
      "\n",
      "            total_failed.add(failed_test)\n",
      "\n",
      "        logger.info(f\"Total failed tests: {len(failed_modules)}\")\n",
      "\n",
      "        # parse error info\n",
      "        pattern = r\"_{2,}(\\s+\\b[\\w\\.]+)(?:\\[\\S+\\])?\\s+_{2,}\\n(.*?)\\n[_|-]\"\n",
      "        test_info = re.findall(pattern, stdout, re.DOTALL)\n",
      "\n",
      "        return {f.strip(): error.rstrip() for f, error in test_info}, len(total_failed)\n",
      "\n",
      "    def get_failed(self, test_name):\n",
      "        \"\"\"\n",
      "        Did test_name fail in this coverage run?\n",
      "        \"\"\"\n",
      "        return self.failed.get(test_name, None)\n",
      "\n",
      "    def __bool__(self):\n",
      "        return bool(self.coverage)\n",
      "\n",
      "    def get_coverage(self):\n",
      "        return self.coverage\n",
      "\n",
      "    # actually parse out the stderr\n",
      "    def get_error(self):\n",
      "        if not self.stderr:\n",
      "            raise Exception(\"No error found\")\n",
      "        return self.stderr\n",
      "  repo/diff.py#44.43\n",
      "----------------------------------------------------------------------\n",
      "class Diff:\n",
      "    def __init__(self, body: str):\n",
      "        self.body = body\n",
      "        self.attrs: DiffAttr = self._parse_patch_attributes()\n",
      "        self.hunks: List[HunkChunk] = self._parse_hunks()\n",
      "        # lets assume this is the most reliable path, because it *should* account\n",
      "        # for new/renamed files\n",
      "        # remove b/ from begining\n",
      "        self.filepath: str = self._find_new_filepath()\n",
      "\n",
      "    def _find_new_filepath(self) -> str:\n",
      "        \"\"\"\n",
      "        Finds the filepath of the b/file\n",
      "        \"\"\"\n",
      "        if self.attrs:\n",
      "            return self.norm_path(self.attrs.b_path_fallback)\n",
      "\n",
      "        # look for the +++ line\n",
      "        for line in self.body.split(\"\\n\"):\n",
      "            if line.startswith(\"+++\"):\n",
      "                return line[3:].strip()\n",
      "\n",
      "    def norm_path(self, path: str) -> str:\n",
      "        \"\"\"\n",
      "        Removes the \"a/\" and \"b/\" prefixes\n",
      "        \"\"\"\n",
      "        return path[2:]\n",
      "\n",
      "    def _parse_hunks(self) -> List[HunkChunk]:\n",
      "        hunks = []\n",
      "        hunk_starts = find_substring(self.body, \"@@\")\n",
      "\n",
      "        try:\n",
      "            start = hunk_starts.pop(0)\n",
      "        except IndexError:\n",
      "            return []\n",
      "\n",
      "        for end in hunk_starts:\n",
      "            hunk_body = self.body[start:end]\n",
      "            start = end\n",
      "            hunks.append(HunkChunk(hunk_body))\n",
      "        hunks.append(HunkChunk(self.body[start:]))  # last hunk\n",
      "\n",
      "        return hunks\n",
      "  repo/repository.py#54.53\n",
      "----------------------------------------------------------------------\n",
      "class GitRepo:\n",
      "\n",
      "    def checkout_and_push(\n",
      "        self,\n",
      "        name: str,\n",
      "        commit_message: str,\n",
      "        files_to_commit: list,\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Checks out a new branch, commits changes, and pushes to the remote. Returns the\n",
      "        URL for the merge request of our new branch against main\n",
      "\n",
      "        Args:\n",
      "        - name: The \"suggested\" name\n",
      "        - commit_message: The commit message to use.\n",
      "        - files_to_commit: List of file paths (relative to the repo root) to commit.\n",
      "\n",
      "        Returns:\n",
      "        - None\n",
      "        \"\"\"\n",
      "        branch_name = name\n",
      "        if self.branch_exists(name):\n",
      "            branch_name = self.branch_prefix + name + \"_\" + gen_random_name()\n",
      "\n",
      "        # Check out a new branch\n",
      "        try:\n",
      "            new_branch = self.repo.create_head(branch_name)\n",
      "            new_branch.checkout()\n",
      "\n",
      "            # Add and commit changes\n",
      "            self.repo.index.add(files_to_commit)\n",
      "            self.repo.index.commit(commit_message)\n",
      "            self.push(branch_name=branch_name)\n",
      "            origin_url = self.origin.url.replace(\".git\", \"\")\n",
      "        except Exception as e:\n",
      "            log.error(f\"Exception in {self.repo_name}: {str(e)}\")\n",
      "            pass\n",
      "        finally:\n",
      "            self.checkout(self.main)\n",
      "            log.info(f\"Resetting to branch {self.main}\")\n",
      "\n",
      "        # url for branch merge request\n",
      "        return f\"{origin_url}/compare/{self.main}...{self.username}:{self.repo_name}:{branch_name}?expand=1\"\n",
      "\n",
      "\n",
      "class PatchApplyExcepion(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class IncompatibleCommit(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class PatchFile(BaseModel):\n",
      "    path: Path\n",
      "    patch: str\n",
      "  repo/runner.py#58.41\n",
      "----------------------------------------------------------------------\n",
      "from abc import ABC, abstractmethod\n",
      "from cowboy_lib.api.runner.shared import RunTestTaskArgs\n",
      "from cowboy_lib.coverage import CoverageResult\n",
      "\n",
      "from typing import Tuple, List, Any\n",
      "\n",
      "\n",
      "class Runner(ABC):\n",
      "    \"\"\"\n",
      "    Runs the lang/framework specific unit test\n",
      "    \"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    def run_test(self, args: RunTestTaskArgs) -> Tuple[CoverageResult, str, str]:\n",
      "        \"\"\"\n",
      "        Run the test and return the coverage result\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def _construct_cmd(\n",
      "        self,\n",
      "        repo_path,\n",
      "        selected_args_str: str = \"\",\n",
      "        deselected_args_str: str = \"\",\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Constructs the cmd for running the test via subprocess\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def _get_include_tests_arg_str(self, include_tests: List[str] = []):\n",
      "        \"\"\"\n",
      "        Constructs the arg string for selecting specific tests\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "\n",
      "    def _get_exclude_tests_arg_str(self, exclude_tests: List[Any]):\n",
      "        \"\"\"\n",
      "        Constructs the arg string for excluding specific tests\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "  test_modules/test_module.py#76.23\n",
      "----------------------------------------------------------------------\n",
      "class TestModule:\n",
      "\n",
      "    def delete_chunk(self, range, filepath):\n",
      "        for c in self.chunks[:]:\n",
      "            if c.range == range and c.filepath == filepath:\n",
      "                self.chunks.remove(c)\n",
      "\n",
      "    def diff_chunks(self, other: \"TestModule\"):\n",
      "        return [c for c in self.chunks if c not in other.chunks]\n",
      "\n",
      "    def print_chunks(self) -> str:\n",
      "        if not self.chunks:\n",
      "            return \"\"\n",
      "\n",
      "        repr = \"\"\n",
      "        repr += f\"Test Module: {self.test_file.path}\\n\"\n",
      "        repr += f\"File: {self.chunks[0].filepath.name}\\n\"\n",
      "\n",
      "        curr_file = self.chunks[0].filepath.name\n",
      "        for c in self.chunks:\n",
      "            if c.filepath.name != curr_file:\n",
      "                curr_file = c.filepath.name\n",
      "                repr += f\"File: {c.filepath.name}\\n\"\n",
      "            repr += c.to_lines()\n",
      "        return repr\n",
      "  cowboy_lib/utils.py#81.37\n",
      "----------------------------------------------------------------------\n",
      "def testfiles_in_coverage(base_cov, src_repo) -> bool:\n",
      "    \"\"\"\n",
      "    Check if the test files are accidentally included in the coverage\n",
      "    \"\"\"\n",
      "    for test_file in src_repo.test_files:\n",
      "        for cov in base_cov.cov_list:\n",
      "            if cov.filename.split(os.sep)[-1] == test_file.path.name:\n",
      "                return True\n",
      "    return False\n",
      "\n",
      "\n",
      "def generate_id():\n",
      "    \"\"\"\n",
      "    Generates a random UUID\n",
      "    \"\"\"\n",
      "    return str(uuid.uuid4())\n",
      "\n",
      "\n",
      "def gen_random_name():\n",
      "    \"\"\"\n",
      "    Generates a random name using ASCII, 8 characters in length\n",
      "    \"\"\"\n",
      "\n",
      "    return \"\".join(random.choices(string.ascii_lowercase, k=8))\n",
      "\n",
      "\n",
      "def find_substring(string: str, substring: str):\n",
      "    indices = []\n",
      "    start = 0\n",
      "    while start < len(string):\n",
      "        start = string.find(substring, start)\n",
      "        if start == -1:  # No more occurrences\n",
      "            return indices\n",
      "        indices.append(start)\n",
      "        start += 1  # Move past the last found index to find subsequent matches\n",
      "\n",
      "    return indices\n",
      "  experiments/augment_test.py#125.28\n",
      "----------------------------------------------------------------------\n",
      "def num_funcs_to_delete(tm: TestModule, to_keep: int = 0, to_delete: int = 0) -> int:\n",
      "    \"\"\"\n",
      "    Returns the number of functions to delete or keep from a test module\n",
      "    \"\"\"\n",
      "    print(\"to_keep: \", to_keep, \"to_delete:\", to_delete)\n",
      "    if to_keep and to_delete:\n",
      "        raise Exception(\"Cannot have both values > 0\")\n",
      "\n",
      "    # always leave at least one test\n",
      "    if to_keep:\n",
      "        num_to_del = max(0, len(tm.tests) - to_keep)\n",
      "        return num_to_del\n",
      "    elif to_delete:\n",
      "        num_to_del = min(len(tm.tests) - 1, to_delete)\n",
      "        return num_to_del\n",
      "    else:\n",
      "        raise ExpVarDeleteFuncs\n",
      "\n",
      "\n",
      "# for every experiment, we potentially create two new branches\n",
      "# br1: keep2\n",
      "# br2: keep2/mod1 or keep2/expid\n",
      "def nuke_name_br(to_keep, to_delete):\n",
      "    branch = f\"{'keep' + str(to_keep) if to_keep else 'del' + str(to_delete)}\"\n",
      "    return branch\n",
      "\n",
      "\n",
      "def exp_name_br(exp_id: str):\n",
      "    return exp_id\n",
      "  queue/core.py#136.41\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.api.runner.shared import Task, TaskStatus\n",
      "\n",
      "from fastapi import Request\n",
      "from threading import Lock\n",
      "from collections import defaultdict\n",
      "from typing import List, Dict\n",
      "from asyncio import Event, wait_for\n",
      "\n",
      "\n",
      "class TaskEvent:\n",
      "    def __init__(self, task: Task):\n",
      "        self.event = Event()\n",
      "        self.task = task\n",
      "        self.result = None\n",
      "\n",
      "    async def wait(self, timeout: float = None):\n",
      "        try:\n",
      "            if timeout:\n",
      "                await wait_for(self.event.wait(), timeout)\n",
      "            else:\n",
      "                await self.event.wait()\n",
      "        except TimeoutError:\n",
      "            return None\n",
      "\n",
      "        return self.result\n",
      "\n",
      "    def complete(self, result):\n",
      "        \"\"\"\n",
      "        Complete with result and signal event to wake up\n",
      "        \"\"\"\n",
      "        self.result = result\n",
      "        self.event.set()\n",
      "\n",
      "    @property\n",
      "    def task_id(self):\n",
      "        return self.task.task_id\n",
      "\n",
      "    def __eq__(self, other):\n",
      "        return self.task_id == other.task_id\n",
      "\n",
      "    # def __hash__(self):\n",
      "    #     return sum([ord(c) for c in self.task_id])\n",
      "  queue/models.py#138.9\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.api.runner.shared import Task\n",
      "\n",
      "\n",
      "class CompleteTaskRequest(Task):\n",
      "    pass\n",
      "\n",
      "\n",
      "class GetTaskResponse(Task):\n",
      "    pass\n",
      "  queue/service.py#140.31\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.api.runner.shared import Task\n",
      "\n",
      "from typing import Optional, List, Dict\n",
      "\n",
      "from src.queue.core import TaskQueue\n",
      "\n",
      "\n",
      "def list_tasks(*, task_queue: TaskQueue, user_id: int, n: int) -> Optional[List[Task]]:\n",
      "    \"\"\"List all tasks in the queue.\"\"\"\n",
      "\n",
      "    return task_queue.peak(user_id, n)\n",
      "\n",
      "\n",
      "def dequeue_task(*, task_queue: TaskQueue, user_id: int) -> Optional[List[Task]]:\n",
      "    \"\"\"Dequeue the first task in the queue: retrieve and delete it.\"\"\"\n",
      "\n",
      "    return task_queue.get_all(user_id)\n",
      "\n",
      "\n",
      "def complete_task(\n",
      "    *, task_queue: TaskQueue, user_id: int, task_id: str, result: Dict\n",
      ") -> None:\n",
      "    \"\"\"Mark a task as completed.\"\"\"\n",
      "    task_queue.complete(user_id, task_id, result)\n",
      "\n",
      "\n",
      "def enqueue_task_and_wait(*, task_queue: TaskQueue, task: Task, user_id: int):\n",
      "    \"\"\"Enqueue a task to the specified queue.\"\"\"\n",
      "\n",
      "    f = task_queue.put(user_id, task)\n",
      "    return f\n",
      "  runner/models.py#157.28\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.repo.repository import PatchFile\n",
      "from cowboy_lib.coverage import CoverageResult, TestCoverage\n",
      "from cowboy_lib.api.runner.shared import TaskResult\n",
      "\n",
      "from fastapi import HTTPException\n",
      "from pydantic import BaseModel, Field, validator\n",
      "\n",
      "\n",
      "class ClientRunnerException(HTTPException):\n",
      "    def __init__(self, msg):\n",
      "        # TODO: make pytest a variable for diff testing frameworks\n",
      "        self.detail = f\"Local pytest runner error: {msg}\"\n",
      "        self.status_code = 400\n",
      "\n",
      "\n",
      "class RunnerExceptionResponse(BaseModel):\n",
      "    exception: str\n",
      "\n",
      "\n",
      "def json_to_coverage_result(res: TaskResult):\n",
      "    if res.exception:\n",
      "        raise ClientRunnerException(res.exception)\n",
      "\n",
      "    cov_results = CoverageResult(\"\", \"\", {})\n",
      "    cov_results.coverage = TestCoverage.deserialize(res.coverage)\n",
      "    cov_results.failed = res.failed\n",
      "\n",
      "    return cov_results\n",
      "  runner/service.py#159.40\n",
      "----------------------------------------------------------------------\n",
      "async def run_test(\n",
      "    repo_name: str,\n",
      "    service_args: RunServiceArgs,\n",
      "    exclude_tests: List[Tuple[Function, str]] = [],\n",
      "    include_tests: List[str] = [],\n",
      "    patch_file: PatchFile = None,\n",
      ") -> CoverageResult:\n",
      "    task = Task(\n",
      "        type=TaskType.RUN_TEST,\n",
      "        task_args=RunTestTaskArgs(\n",
      "            repo_name=repo_name,\n",
      "            patch_file=patch_file,\n",
      "            exclude_tests=[((f.name, f.is_meth()), path) for f, path in exclude_tests],\n",
      "            include_tests=include_tests,\n",
      "        ),\n",
      "    )\n",
      "\n",
      "    future = enqueue_task_and_wait(\n",
      "        task_queue=service_args.task_queue,\n",
      "        user_id=service_args.user_id,\n",
      "        task=task,\n",
      "    )\n",
      "    res = await future.wait()\n",
      "\n",
      "    cov_res = json_to_coverage_result(res)\n",
      "    return cov_res\n",
      "\n",
      "\n",
      "async def shutdown_client(\n",
      "    service_args: RunServiceArgs,\n",
      ") -> CoverageResult:\n",
      "    task = Task(type=TaskType.SHUTDOWN)\n",
      "\n",
      "    future = enqueue_task_and_wait(\n",
      "        task_queue=service_args.task_queue,\n",
      "        user_id=service_args.user_id,\n",
      "        task=task,\n",
      "    )\n",
      "\n",
      "    await future.wait(timeout=3)\n",
      "  tasks/create_tgt_coverage.py#177.46\n",
      "----------------------------------------------------------------------\n",
      "# TODO:\n",
      "@async_timed\n",
      "async def create_tgt_coverage(\n",
      "    *,\n",
      "    db_session: Session,\n",
      "    task_queue: TaskQueue,\n",
      "    repo: RepoConfig,\n",
      "    tm_models: List[TestModuleModel],\n",
      "    overwrite: bool = True,\n",
      "):\n",
      "    \"\"\"\n",
      "    Important function that sets up relationships between TestModule, TargetCode and\n",
      "    Coverage\n",
      "    \"\"\"\n",
      "    src_repo = SourceRepo(Path(repo.source_folder))\n",
      "    run_args = RunServiceArgs(repo.user_id, task_queue)\n",
      "    base_cov = repo.base_cov\n",
      "\n",
      "    if overwrite or not base_cov:\n",
      "        cov_res = await run_test(repo.repo_name, run_args)\n",
      "        base_cov = cov_res.coverage\n",
      "        upsert_coverage(\n",
      "            db_session=db_session, repo_id=repo.id, cov_list=base_cov.cov_list\n",
      "        )\n",
      "\n",
      "    for tm_model in tm_models:\n",
      "        # only overwrite existing target_chunks if overwrite flag is set\n",
      "        if not overwrite and tm_model.target_chunks:\n",
      "            log.info(f\"Skipping TM {tm_model.name}\")\n",
      "            continue\n",
      "\n",
      "        tm = tm_model.serialize(src_repo)\n",
      "        # generate src to test mappings\n",
      "        targets = await get_tm_target_coverage(\n",
      "            repo.repo_name, src_repo, tm, base_cov, run_args\n",
      "        )\n",
      "        # store chunks and their nodes\n",
      "        tgt_code_chunks = create_tgt_code_models(targets, db_session, repo.id, tm_model)\n",
      "\n",
      "        # TODO: convert this to a Logfire log?\n",
      "        print(f\"{tm_model.name} Chunks: \")\n",
      "        for t in tgt_code_chunks:\n",
      "            print(t.to_str())\n",
      "\n",
      "        tm_model.target_chunks = tgt_code_chunks\n",
      "        update_tm(db_session=db_session, tm_model=tm_model)\n",
      "  tasks/get_baseline.py#181.77\n",
      "----------------------------------------------------------------------\n",
      "async def get_tm_target_coverage(\n",
      "    repo_name: str,\n",
      "    src_repo: SourceRepo,\n",
      "    tm: TestModule,\n",
      "    base_cov: CoverageResult,\n",
      "    run_args: RunServiceArgs,\n",
      ") -> Tuple[TestModule, List[TargetCode]]:\n",
      "    \"\"\"\n",
      "    Test augmenting existing test classes by deleting random test methods, and then\n",
      "    having LLM strategy generate them. Coverage is taken:\n",
      "    1. After the deletion\n",
      "    2. After the deletion with newly generated LLM testcases\n",
      "\n",
      "    The diff measures how well we are able to supplant the coverage of the deleted methods\n",
      "    \"\"\"\n",
      "\n",
      "    if testfiles_in_coverage(base_cov.coverage, src_repo):\n",
      "        raise TestInCoverageException\n",
      "\n",
      "    # First loop we find the total coverage of each test by itself\n",
      "    only_module = [tm.name]\n",
      "    # coverage with ONLY the current test module turned on\n",
      "    print(\"Running initial test ... \", tm.name)\n",
      "\n",
      "    module_cov = await run_test(\n",
      "        repo_name,\n",
      "        run_args,\n",
      "        include_tests=only_module,\n",
      "    )\n",
      "\n",
      "    module_diff = base_cov.coverage - module_cov.coverage\n",
      "    total_cov_diff = module_diff.total_cov.covered\n",
      "    if total_cov_diff > 0:\n",
      "        # part 2:\n",
      "        single_covs = []\n",
      "        for test in tm.tests:\n",
      "            print(\"Running test ... \", test.name)\n",
      "            # tm.test_file.delete(test.name, node_type=test.type)\n",
      "            # deleted_file = PatchFile(tm.test_file.path, tm.test_file.to_code())\n",
      "            # with PatchFileContext(repo_ctxt.git_repo, deleted_file):\n",
      "\n",
      "            # exclude_test = get_exclude_path(test, tm.test_file.path)\n",
      "            single_cov = await run_test(\n",
      "                repo_name,\n",
      "                run_args,\n",
      "                exclude_tests=[(test, tm.test_file.path)],\n",
      "                include_tests=only_module,\n",
      "            )\n",
      "            print(\"Test results: \", single_cov.coverage.total_cov.covered)\n",
      "\n",
      "            print(\n",
      "                f\"Module cov: {module_cov.coverage.total_cov.covered}, Single cov: {single_cov.coverage.total_cov.covered}\"\n",
      "            )\n",
      "\n",
      "            single_diff = (module_cov.coverage - single_cov.coverage).cov_list\n",
      "            for c in single_diff:\n",
      "                logger.info(\n",
      "                    f\"Changed coverage from deleting {test.name}:\\n {c.__str__()}\"\n",
      "                )\n",
      "\n",
      "            # dont think we actually need this here .. confirm\n",
      "            tm.test_file = src_repo.find_file(tm.test_file.path)\n",
      "            single_covs.extend(single_diff)\n",
      "\n",
      "        # re-init the chunks according to the aggregated individual test coverages\n",
      "        tm.set_chunks(\n",
      "            single_covs,\n",
      "            source_repo=src_repo,\n",
      "            base_path=src_repo.repo_path,\n",
      "        )\n",
      "\n",
      "        print(f\"Chunks: \\n{tm.print_chunks()}\")\n",
      "    # Find out what's the reason for the missed tests\n",
      "    else:\n",
      "        logger.info(f\"No coverage difference found for {tm.name}\")\n",
      "\n",
      "    return tm, tm.chunks\n",
      "  tasks/get_baseline_parallel.py#184.79\n",
      "----------------------------------------------------------------------\n",
      "async def get_tm_target_coverage(\n",
      "    repo_name: str,\n",
      "    src_repo: SourceRepo,\n",
      "    tm: TestModule,\n",
      "    base_cov: TestCoverage,\n",
      "    run_args: RunServiceArgs,\n",
      ") -> List[TargetCode]:\n",
      "    \"\"\"\n",
      "    Test augmenting existing test classes by deleting random test methods, and then\n",
      "    having LLM strategy generate them. Coverage is taken:\n",
      "    1. After the deletion\n",
      "    2. After the deletion with newly generated LLM testcases\n",
      "\n",
      "    The diff measures how well we are able to supplant the coverage of the deleted methods\n",
      "    \"\"\"\n",
      "\n",
      "    if testfiles_in_coverage(base_cov, src_repo):\n",
      "        raise TestInCoverageException\n",
      "\n",
      "    # First loop we find the total coverage of each test by itself\n",
      "    only_module = [tm.name]\n",
      "    # coverage with ONLY the current test module turned on\n",
      "    print(\"Running initial test ... \", tm.name)\n",
      "\n",
      "    # TODO: should be storing this as well\n",
      "    module_cov = await run_test(\n",
      "        repo_name,\n",
      "        run_args,\n",
      "        include_tests=only_module,\n",
      "    )\n",
      "\n",
      "    module_diff = base_cov - module_cov.coverage\n",
      "    total_cov_diff = module_diff.total_cov.covered\n",
      "    if total_cov_diff > 0:\n",
      "        # part 2:\n",
      "        # holds the coverage diff of individual tests after they have\n",
      "        # been selectively turned off\n",
      "        chg_cov = []\n",
      "        coroutines = []\n",
      "\n",
      "        for test in tm.tests:\n",
      "            print(\"Running test ... \", test.name)\n",
      "            task = run_test(\n",
      "                repo_name,\n",
      "                run_args,\n",
      "                exclude_tests=[(test, tm.test_file.path)],\n",
      "                include_tests=only_module,\n",
      "            )\n",
      "            coroutines.append(task)\n",
      "\n",
      "        cov_res = await asyncio.gather(*[t for t in coroutines])\n",
      "        for test, cov_res in zip(tm.tests, cov_res):\n",
      "            print(\"Test results: \", cov_res.coverage.total_cov.covered)\n",
      "            print(\n",
      "                f\"Module cov: {module_cov.coverage.total_cov.covered}, Single cov: {cov_res.coverage.total_cov.covered}\"\n",
      "            )\n",
      "\n",
      "            single_diff = (module_cov.coverage - cov_res.coverage).cov_list\n",
      "            for c in single_diff:\n",
      "                logger.info(\n",
      "                    f\"Changed coverage from deleting {test.name}:\\n {c.__str__()}\"\n",
      "                )\n",
      "\n",
      "            # dont think we actually need this here .. confirm\n",
      "            chg_cov.extend(single_diff)\n",
      "\n",
      "        # re-init the chunks according to the aggregated individual test coverages\n",
      "        chunks = set_chunks(\n",
      "            chg_cov,\n",
      "            source_repo=src_repo,\n",
      "            base_path=src_repo.repo_path,\n",
      "        )\n",
      "\n",
      "    # Find out what's the reason for the missed tests\n",
      "    else:\n",
      "        logger.info(f\"No coverage difference found for {tm.name}\")\n",
      "        return []\n",
      "\n",
      "    return chunks\n",
      "  evaluators/augment_additive.py#194.60\n",
      "----------------------------------------------------------------------\n",
      "class AugmentAdditiveEvaluator(Evaluator):\n",
      "    async def process_test_results(\n",
      "        self,\n",
      "        test_results: List[Tuple[CoverageResult, str]],\n",
      "        tm: \"TestModule\",\n",
      "        base_cov: TestCoverage,\n",
      "    ) -> Tuple[\n",
      "        List[Tuple[Function, TestCoverage]],\n",
      "        List[Tuple[Function, TestError]],\n",
      "        List[Function],\n",
      "    ]:\n",
      "        \"\"\"\n",
      "        Sequentially build a set of coverage improving testcases, discarding any\n",
      "        generated tests that dont contribute coverage improvements\n",
      "        \"\"\"\n",
      "        improved_tests: List[Tuple[Function, TestCoverage]] = []\n",
      "        failed_tests: List[Tuple[Function, TestError]] = []\n",
      "        noimprov_tests: List[Function] = []\n",
      "\n",
      "        for cov_res, cov_diff, test_file in test_results:\n",
      "            if cov_diff:\n",
      "                new_funcs = self.get_new_funcs(test_file, tm.path)\n",
      "                # iterate each generated function and measure if it has coverage\n",
      "                # improvement against the base\n",
      "                for func in new_funcs:\n",
      "                    test_error = cov_res.get_failed(func.name)\n",
      "                    if test_error:\n",
      "                        testgen_logger.info(f\"[FAILED] Generated Func: {func.name}\")\n",
      "                        testgen_logger.info(f\"Code: {func.to_code()}\")\n",
      "\n",
      "                        failed_tests.append((func, test_error))\n",
      "                        continue\n",
      "\n",
      "                    # TODO: make sure that this works for filename TMs as well\n",
      "                    og_testfile = self.src_repo.find_file(tm.path).clone()\n",
      "                    og_testfile.append(\n",
      "                        func.to_code(), class_name=func.scope.name if func.scope else \"\"\n",
      "                    )\n",
      "\n",
      "                    patch_file = PatchFile(\n",
      "                        path=str(tm.path), patch=og_testfile.to_code()\n",
      "                    )\n",
      "                    indvtest_cov = await run_test(\n",
      "                        self.repo_name,\n",
      "                        self.run_args,\n",
      "                        patch_file=patch_file,\n",
      "                    )\n",
      "\n",
      "                    indv_improve = indvtest_cov.coverage - base_cov\n",
      "                    if indv_improve.total_cov.covered > 0:\n",
      "                        testgen_logger.info(f\"[IMPROVE] Generated Func: {func.name}\")\n",
      "                        testgen_logger.info(f\"Code: {func.to_code()}\")\n",
      "\n",
      "                        improved_tests.append((func, indv_improve))\n",
      "                    else:\n",
      "                        testgen_logger.info(f\"[NOIMPROVE] Generated Func: {func.name}\")\n",
      "                        testgen_logger.info(f\"Code: {func.to_code()}\")\n",
      "\n",
      "                        noimprov_tests.append((func, TestCoverage([])))\n",
      "\n",
      "        return improved_tests, failed_tests, noimprov_tests\n",
      "  evaluators/augment_parallel.py#195.46\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.coverage import CoverageResult, TestError, TestCoverage\n",
      "from cowboy_lib.repo.repository import PatchFile\n",
      "from cowboy_lib.repo.source_file import Function\n",
      "\n",
      "from typing import Tuple, List, TYPE_CHECKING\n",
      "\n",
      "if TYPE_CHECKING:\n",
      "    from test_gen.augment_test.types import StratResult\n",
      "    from cowboy_lib.test_modules import TestModule\n",
      "\n",
      "from .eval_base import Evaluator\n",
      "\n",
      "from concurrent.futures import ThreadPoolExecutor\n",
      "from src.logger import testgen_logger\n",
      "\n",
      "\n",
      "class AugmentParallelEvaluator(Evaluator):\n",
      "    \"\"\"\n",
      "    Used to evaluate the results of a test strategy\n",
      "    \"\"\"\n",
      "\n",
      "    async def __call__(\n",
      "        self,\n",
      "        llm_results: List[\"StratResult\"],\n",
      "        tm: \"TestModule\",\n",
      "        base_cov: CoverageResult,\n",
      "        n_times: int = 1,\n",
      "    ) -> Tuple[\n",
      "        List[Tuple[Function, TestCoverage]],\n",
      "        List[Tuple[Function, TestError]],\n",
      "        List[Function],\n",
      "    ]:\n",
      "        \"\"\"\n",
      "        Main eval method, accepts a list of results from the strategy and the\n",
      "        targeted test module, and a baseline coverage to compare against\n",
      "        \"\"\"\n",
      "        test_fp = tm.test_file.path\n",
      "        test_results = await self.gen_test_and_diff_coverage(\n",
      "            llm_results, base_cov, test_fp, n_times\n",
      "        )\n",
      "        improved, failed, no_improve = await self.process_test_results(\n",
      "            test_results, tm, base_cov\n",
      "        )\n",
      "\n",
      "        return improved, failed, no_improve\n",
      "\n",
      "    # questionable decision to make non-existent func Functions ..\n",
      "  evaluators/augment_parallel.py#196.83\n",
      "----------------------------------------------------------------------\n",
      "class AugmentParallelEvaluator(Evaluator):\n",
      "    async def process_test_results(\n",
      "        self,\n",
      "        test_results: List[Tuple[CoverageResult, str]],\n",
      "        tm: \"TestModule\",\n",
      "        del_cov: CoverageResult,\n",
      "    ) -> Tuple[\n",
      "        List[Tuple[Function, TestCoverage]],\n",
      "        List[Tuple[Function, TestError]],\n",
      "        List[Function],\n",
      "    ]:\n",
      "        \"\"\"\n",
      "        Takes the results from run_test and processes it into a list of\n",
      "        coverage enhancing test cases and failed tests\n",
      "        \"\"\"\n",
      "        improved_tests: List[Tuple[Function, TestCoverage]] = []\n",
      "        failed_tests: List[Tuple[Function, TestError]] = []\n",
      "        noimprov_tests: List[Function] = []\n",
      "\n",
      "        for cov_res, cov_diff, test_file in test_results:\n",
      "            if cov_diff:\n",
      "                new_funcs = self.get_new_funcs(test_file, tm.path)\n",
      "                # 1. create args for each runner thread\n",
      "                runner_args = {}\n",
      "                for func in new_funcs:\n",
      "                    test_error = cov_res.get_failed(func.name)\n",
      "                    if test_error:\n",
      "                        testgen_logger.info(f\"[FAILED] Generated Func: {func.name}\")\n",
      "                        testgen_logger.info(f\"Code: {func.to_code()}\")\n",
      "\n",
      "                        failed_tests.append((func, test_error))\n",
      "                        continue\n",
      "\n",
      "                    # TODO: make sure that this works for filename TMs as well\n",
      "                    og_testfile = self.src_repo.find_file(tm.path).clone()\n",
      "                    og_testfile.append(\n",
      "                        func.to_code(), class_name=func.scope.name if func.scope else \"\"\n",
      "                    )\n",
      "\n",
      "                    patch_file = PatchFile(path=tm.path, patch=og_testfile.to_code())\n",
      "                    runner_args[func] = {\"patch_file\": patch_file}\n",
      "\n",
      "                # 2. run tests in parallel\n",
      "                results = []\n",
      "                with ThreadPoolExecutor(max_workers=4) as executor:\n",
      "                    futures = [\n",
      "                        (func, executor.submit(self.runner.run_test, **args))\n",
      "                        for func, args in runner_args.items()\n",
      "                    ]\n",
      "                    testgen_logger.info(\n",
      "                        f\"{len(futures)} tests submitted for evaluation\"\n",
      "                    )\n",
      "                    for func, future in futures:\n",
      "                        results.append((func, future.result()))\n",
      "\n",
      "                # 3. loop through test_results and update\n",
      "                for func, res in results:\n",
      "                    indvtest_cov, *_ = res\n",
      "\n",
      "                    indv_improve = indvtest_cov.coverage - del_cov.coverage\n",
      "                    if indv_improve.total_cov.covered > 0:\n",
      "                        testgen_logger.info(f\"[IMPROVE] Generated Func: {func.name}\")\n",
      "                        testgen_logger.info(f\"Code: {func.to_code()}\")\n",
      "\n",
      "                        improved_tests.append((func, indv_improve))\n",
      "                    else:\n",
      "                        testgen_logger.info(f\"[NOIMPROVE] Generated Func: {func.name}\")\n",
      "                        testgen_logger.info(f\"Code: {func.to_code()}\")\n",
      "\n",
      "                        noimprov_tests.append((func, TestCoverage([])))\n",
      "\n",
      "                # MOVE into post analysis\n",
      "                # log improvements or something\n",
      "                # tgt_file = tm.targeted_files(base_path=False)[0]\n",
      "                # tgt_file_after = cov_res.coverage.get_file_cov(tgt_file)\n",
      "                # if tgt_file_after:\n",
      "                #     logger.info(\n",
      "                #         f\"Target file improvement: {tgt_file_after.covered if tgt_file_after else 0}/{tgt_cov}\"\n",
      "                #     )\n",
      "                # logger.info(\n",
      "                #     f\"Improvement: {cov_res.coverage.total_cov.covered}/{total_cov}\"\n",
      "                # )\n",
      "\n",
      "        return improved_tests, failed_tests, noimprov_tests\n",
      "  evaluators/eval_base.py#198.38\n",
      "----------------------------------------------------------------------\n",
      "class Evaluator(ABC):\n",
      "    def __init__(\n",
      "        self, repo_name: str, src_repo: \"SourceRepo\", run_args: RunServiceArgs\n",
      "    ):\n",
      "        self.repo_name = repo_name\n",
      "        self.src_repo = src_repo\n",
      "        self.run_args = run_args\n",
      "\n",
      "    async def gen_test_and_diff_coverage(\n",
      "        self,\n",
      "        strat_results: List[\"StratResult\"],\n",
      "        base_cov: TestCoverage,\n",
      "        test_fp: Path,\n",
      "        n_times: int = 1,\n",
      "    ) -> List[Tuple[CoverageResult, TestCoverage]]:\n",
      "        \"\"\"\n",
      "        Does two runs:\n",
      "        1. Run to get coverage baseline\n",
      "        2. Run with generated test case\n",
      "        Return diff in coverage, and generated test case\n",
      "        \"\"\"\n",
      "        test_results = []\n",
      "        total_cost = 0\n",
      "\n",
      "        # WARNING: for some reason failures here are not recorded fully for every new individual\n",
      "        # that is generate. Possibly due to failures cascading?\n",
      "        for i, (test_file, test_funcs) in enumerate(strat_results, start=1):\n",
      "            patch_file = PatchFile(path=test_fp, patch=test_file)\n",
      "            cov_ptched = await run_test(\n",
      "                self.repo_name, self.run_args, patch_file=patch_file\n",
      "            )\n",
      "            cov_diff = cov_ptched.coverage - base_cov\n",
      "            # TODO: this covered number is off check\n",
      "            testgen_logger.info(\n",
      "                f\"New coverage from generated tests: {cov_diff.total_cov.covered}\"\n",
      "            )\n",
      "            test_results.append((cov_ptched, cov_diff, test_file))\n",
      "\n",
      "        return test_results\n",
      "  evaluators/eval_base.py#199.36\n",
      "----------------------------------------------------------------------\n",
      "class Evaluator(ABC):\n",
      "\n",
      "    def get_new_funcs(\n",
      "        self,\n",
      "        new_testfile: str,\n",
      "        test_fp: Path,\n",
      "    ) -> List[Function]:\n",
      "        \"\"\"\n",
      "        Get newly generated functions\n",
      "        \"\"\"\n",
      "        new_testfile = TestFile(lines=new_testfile.split(\"\\n\"), path=str(test_fp))\n",
      "        old_testfile: TestFile = self.src_repo.find_file(test_fp)\n",
      "        new_funcs = old_testfile.new_test_funcs(new_testfile)\n",
      "\n",
      "        return new_funcs\n",
      "\n",
      "    @abstractmethod\n",
      "    async def __call__(\n",
      "        self,\n",
      "        llm_results: List[\"StratResult\"],\n",
      "        tm: \"TestModule\",\n",
      "        base_cov: CoverageResult,\n",
      "        n_times: int = 1,\n",
      "    ):\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    async def process_test_results(\n",
      "        self,\n",
      "        test_results: List[Tuple[CoverageResult, str]],\n",
      "        tm: \"TestModule\",\n",
      "        del_cov: CoverageResult,\n",
      "    ) -> Tuple[\n",
      "        List[Tuple[Function, TestCoverage]],\n",
      "        List[Tuple[Function, TestError]],\n",
      "        List[Function],\n",
      "    ]:\n",
      "        raise NotImplementedError\n",
      "Cluster 2\n",
      "  repo/diff.py#43.27\n",
      "----------------------------------------------------------------------\n",
      "class HunkChunk:\n",
      "\n",
      "    def _new_func_decl(self) -> str:\n",
      "        \"\"\"\n",
      "        If the hunk declares a new test function, return it\n",
      "        \"\"\"\n",
      "        # Hunk can be empty since we are only currently looking at + lines\n",
      "        # if len(self.lines) == 0:\n",
      "        #     return \"\"\n",
      "\n",
      "        PYTHON_FUN_DEF = r\"\\+?\\s*(?:async\\s+)?def\\s+([a-zA-Z_][a-zA-Z_0-9]*)\\s*\\(\"\n",
      "        match = re.search(PYTHON_FUN_DEF, self.body)\n",
      "        if match:\n",
      "            return match.group(1)\n",
      "        else:\n",
      "            return \"\"\n",
      "\n",
      "\n",
      "class DiffMode(Enum):\n",
      "    MODIFIED = \"modified\"\n",
      "    DELETED = \"deleted\"\n",
      "    NEW = \"new\"\n",
      "    UNKNOWN = \"unknown\"\n",
      "\n",
      "\n",
      "class DiffAttr(NamedTuple):\n",
      "    a_path: str\n",
      "    b_path: Optional[str]\n",
      "    b_path_fallback: str  # have no idea wtf this thing is\n",
      "    mode: DiffMode\n",
      "  auth/models.py#91.23\n",
      "----------------------------------------------------------------------\n",
      "class CowboyUser(Base, TimeStampMixin):\n",
      "    __tablename__ = \"cowboy_user\"\n",
      "\n",
      "    id = Column(Integer, primary_key=True)\n",
      "    email = Column(String, unique=True)\n",
      "    password = Column(LargeBinary, nullable=False)\n",
      "    last_mfa_time = Column(DateTime, nullable=True)\n",
      "    experimental_features = Column(Boolean, default=False)\n",
      "    admin = Column(Boolean, default=False)\n",
      "\n",
      "    repos = relationship(\n",
      "        \"RepoConfig\", backref=\"cowboy_user\", cascade=\"all, delete-orphan\"\n",
      "    )\n",
      "\n",
      "    # search_vector = Column(\n",
      "    #     TSVectorType(\"email\", regconfig=\"pg_catalog.simple\", weights={\"email\": \"A\"})\n",
      "    # )\n",
      "\n",
      "    def check_password(self, password):\n",
      "        return bcrypt.checkpw(password.encode(\"utf-8\"), self.password)\n",
      "\n",
      "    @property\n",
      "    def token(self):\n",
      "        return generate_token(self.email)\n",
      "  auth/service.py#97.22\n",
      "----------------------------------------------------------------------\n",
      "def create(*, db_session, user_in: UserRegister | UserCreate) -> CowboyUser:\n",
      "    \"\"\"Creates a new dispatch user.\"\"\"\n",
      "    # pydantic forces a string password, but we really want bytes\n",
      "    password = bytes(user_in.password, \"utf-8\")\n",
      "\n",
      "    # create the user\n",
      "    user = CowboyUser(\n",
      "        **user_in.dict(exclude={\"password\", \"openai_api_key\"}),\n",
      "        password=password,\n",
      "    )\n",
      "    db_session.add(user)\n",
      "    db_session.commit()\n",
      "\n",
      "    print(\"Token: \", user.token)\n",
      "    # create the credentials\n",
      "    store_oai_key(user_in.openai_api_key, user.id)\n",
      "\n",
      "    return user\n",
      "\n",
      "\n",
      "def get_user_token(*, db_session, user_id):\n",
      "    user = get(db_session=db_session, user_id=user_id)\n",
      "    return generate_token(user.email)\n",
      "  auth/views.py#105.20\n",
      "----------------------------------------------------------------------\n",
      "@auth_router.get(\"/user/delete\")\n",
      "async def delete_user(\n",
      "    curr_user: CowboyUser = Depends(get_current_user),\n",
      "    db_session: Session = Depends(get_db),\n",
      "    task_queue: TaskQueue = Depends(get_queue),\n",
      "):\n",
      "    user = get(db_session=db_session, user_id=curr_user.id)\n",
      "    if not user:\n",
      "        raise HTTPException(\n",
      "            status_code=status.HTTP_404_NOT_FOUND,\n",
      "            detail=\"User not found\",\n",
      "        )\n",
      "\n",
      "    # resets the client to get it to sync with the deleted user\n",
      "    args = RunServiceArgs(user_id=user.id, task_queue=task_queue)\n",
      "    await shutdown_client(args)\n",
      "\n",
      "    db_session.delete(user)\n",
      "    db_session.commit()\n",
      "\n",
      "    return HTTPSuccess()\n",
      "  coverage/service.py#114.35\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.coverage import Coverage\n",
      "from src.test_gen.models import AugmentTestResult\n",
      "\n",
      "from .models import CoverageModel\n",
      "\n",
      "from sqlalchemy.orm import Session\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def upsert_coverage(\n",
      "    *,\n",
      "    db_session: Session,\n",
      "    repo_id: int,\n",
      "    cov_list: List[Coverage],\n",
      "    test_result_id: int = None\n",
      "):\n",
      "    \"\"\"Deletes old coverage and insert new\"\"\"\n",
      "\n",
      "    db_session.query(CoverageModel).filter(CoverageModel.repo_id == repo_id).delete()\n",
      "\n",
      "    for coverage in cov_list:\n",
      "        # if it does not exist, create\n",
      "        cov_model = CoverageModel(\n",
      "            filename=coverage.filename,\n",
      "            covered_lines=\",\".join(map(str, coverage.covered_lines)),\n",
      "            missing_lines=\",\".join(map(str, coverage.missing_lines)),\n",
      "            stmts=coverage.stmts,\n",
      "            misses=coverage.misses,\n",
      "            covered=coverage.covered,\n",
      "            repo_id=repo_id,\n",
      "            test_result_id=test_result_id,\n",
      "        )\n",
      "        db_session.add(cov_model)\n",
      "\n",
      "    db_session.commit()\n",
      "    return cov_model\n",
      "  experiments/augment_test.py#128.16\n",
      "----------------------------------------------------------------------\n",
      "def run_experiment(\n",
      "    repo: RepoConfig,\n",
      "    test_modules: List[TestModuleModel],\n",
      "    to_keep: int = 0,\n",
      "    to_delete: int = 0,\n",
      "):\n",
      "    #     continue\n",
      "\n",
      "    # except SameNodeException as e:\n",
      "    #     logger.info(f\"SameNodeException on class: {tm.name}\")\n",
      "    #     continue\n",
      "\n",
      "    # except Exception as e:\n",
      "    #     logger.info(\n",
      "    #         f\"Exception on class: {tm.name} in {tm.path}\",\n",
      "    #         exc_info=True,\n",
      "    #     )\n",
      "\n",
      "    # logger.info(f\"Final Results: {results}\")\n",
      "    # logger.info(f\"Total improvement: {total_improvement}/{total_coverage}\")\n",
      "    # logger.info(f\"Zero improvement tests: {zero_improvement_tests}\")\n",
      "    # logger.info(f\"Run complete for {self.repo_ctxt.exp_id} \")\n",
      "  queue/core.py#137.94\n",
      "----------------------------------------------------------------------\n",
      "class TaskQueue:\n",
      "    \"\"\"\n",
      "    A set of queues separated by user_id\n",
      "    \"\"\"\n",
      "\n",
      "    _instance = None\n",
      "\n",
      "    def __new__(cls, *args, **kwargs):\n",
      "        if not isinstance(cls._instance, cls):\n",
      "            print(\"Creating new TaskQueue instance\")\n",
      "            cls._instance = super(TaskQueue, cls).__new__(cls, *args, **kwargs)\n",
      "            cls._instance._initialized = False\n",
      "\n",
      "        return cls._instance\n",
      "\n",
      "    def __init__(self):\n",
      "        if not self._initialized:\n",
      "            # Initialize instance variables only once\n",
      "            self.queue: Dict[str, List[TaskEvent]] = defaultdict(list)\n",
      "            self.locks = defaultdict(list)\n",
      "            self._initialized = True  # Mark as initialized\n",
      "\n",
      "    def _acquire_lock(self, user_id: int):\n",
      "        if self.locks.get(user_id, None) is None:\n",
      "            self.locks[user_id] = Lock()\n",
      "        return self.locks.get(user_id)\n",
      "\n",
      "    def put(self, user_id: int, task: str) -> TaskEvent:\n",
      "        with self._acquire_lock(user_id):\n",
      "            t = TaskEvent(task)\n",
      "            self.queue[user_id].append(t)\n",
      "\n",
      "            return t\n",
      "\n",
      "    def complete(self, user_id: int, task_id: str, res):\n",
      "        with self._acquire_lock(user_id):\n",
      "            for i in range(len(self.queue[user_id])):\n",
      "                if self.queue[user_id][i].task_id == task_id:\n",
      "                    t = self.queue[user_id].pop(i)\n",
      "                    t.complete(res)\n",
      "                    break\n",
      "\n",
      "    # def get(self, user_id: int) -> Task:\n",
      "    #     \"\"\"\n",
      "    #     Returns the first PENDING task and changes its status to STARTED\n",
      "    #     \"\"\"\n",
      "    #     with self._acquire_lock(user_id):\n",
      "    #         if len(self.queue[user_id]) == 0:\n",
      "    #             return None\n",
      "\n",
      "    #         return self.queue[user_id].pop()\n",
      "\n",
      "    def get_all(self, user_id: int) -> List[Task]:\n",
      "        with self._acquire_lock(user_id):\n",
      "            if len(self.queue[user_id]) == 0:\n",
      "                return []\n",
      "\n",
      "            tasks = []\n",
      "            for t in filter(\n",
      "                lambda t: t.task.status == TaskStatus.PENDING.value, self.queue[user_id]\n",
      "            ):\n",
      "                t.task.status = TaskStatus.STARTED.value\n",
      "                tasks.append(t.task)\n",
      "\n",
      "            return tasks\n",
      "\n",
      "    def peak(self, user_id: int, n: int) -> List[Task]:\n",
      "        \"\"\"\n",
      "        Get the first n tasks in queue without removing\n",
      "        \"\"\"\n",
      "        with self._acquire_lock(user_id):\n",
      "            if len(self.queue[user_id]) == 0:\n",
      "                return []\n",
      "\n",
      "            return [t.task for t in self.queue[user_id][:n]]\n",
      "\n",
      "\n",
      "def get_queue(request: Request):\n",
      "    return request.state.task_queue\n",
      "\n",
      "\n",
      "def get_token_registry(request: Request):\n",
      "    from main import token_registry\n",
      "\n",
      "    return token_registry\n",
      "\n",
      "\n",
      "def get_token(request: Request):\n",
      "    \"\"\"\n",
      "    Returns the user id\n",
      "    \"\"\"\n",
      "    token = request.headers.get(\"x-task-auth\", None)\n",
      "    # need this or else we end up converting None to \"None\" **shakes fist @ python moment\"\n",
      "    return str(token) if token else None\n",
      "  repo/models.py#143.87\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.coverage import TestCoverage\n",
      "\n",
      "from sqlalchemy import Column, Integer, String, JSON, ForeignKey, Boolean\n",
      "from sqlalchemy.orm import relationship\n",
      "from pydantic import Field\n",
      "\n",
      "from src.models import CowboyBase\n",
      "from src.database.core import Base\n",
      "from src.config import Language\n",
      "\n",
      "from typing import List, Any, Dict, Optional\n",
      "\n",
      "\n",
      "class RepoConfig(Base):\n",
      "    \"\"\"\n",
      "    Stores configuration for a repository\n",
      "    \"\"\"\n",
      "\n",
      "    __tablename__ = \"repo_config\"\n",
      "\n",
      "    id = Column(Integer, primary_key=True)\n",
      "    repo_name = Column(String)\n",
      "    url = Column(String)\n",
      "    source_folder = Column(String)\n",
      "    cloned_folders = Column(String)\n",
      "    # git remote and git main branch (to merge into)\n",
      "    remote = Column(String)\n",
      "    main = Column(String)\n",
      "    language = Column(String)\n",
      "\n",
      "    # keep this argument fluid, may change\n",
      "    python_conf = Column(JSON)\n",
      "    user_id = Column(Integer, ForeignKey(\"cowboy_user.id\"))\n",
      "    is_experiment = Column(Boolean)\n",
      "\n",
      "    # relations\n",
      "    test_modules = relationship(\n",
      "        \"TestModuleModel\", backref=\"repo_config\", cascade=\"all, delete-orphan\"\n",
      "    )\n",
      "    nodes = relationship(\n",
      "        \"NodeModel\", backref=\"repo_config\", cascade=\"all, delete-orphan\"\n",
      "    )\n",
      "    cov_list = relationship(\n",
      "        \"CoverageModel\", backref=\"repo_config\", cascade=\"all, delete-orphan\"\n",
      "    )\n",
      "    stats = relationship(\"RepoStats\", uselist=False, cascade=\"all, delete-orphan\")\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        repo_name,\n",
      "        url,\n",
      "        source_folder,\n",
      "        cloned_folders,\n",
      "        python_conf,\n",
      "        user_id,\n",
      "        remote,  # origin\n",
      "        main,\n",
      "        language,\n",
      "        is_experiment=False,\n",
      "    ):\n",
      "        self.repo_name = repo_name\n",
      "        self.url = url\n",
      "        self.source_folder = source_folder\n",
      "        self.cloned_folders = \",\".join(cloned_folders)\n",
      "        self.python_conf = python_conf\n",
      "        self.user_id = user_id\n",
      "        self.remote = remote\n",
      "        self.main = main\n",
      "        self.language = language\n",
      "        self.is_experiment = is_experiment\n",
      "\n",
      "    def to_dict(self):\n",
      "        return {\n",
      "            \"repo_name\": self.repo_name,\n",
      "            \"url\": self.url,\n",
      "            \"source_folder\": self.source_folder,\n",
      "            \"cloned_folders\": self.cloned_folders.split(\",\"),\n",
      "            \"python_conf\": self.python_conf,\n",
      "            \"user_id\": self.user_id,\n",
      "            \"remote\": self.remote,\n",
      "            \"main\": self.main,\n",
      "            \"language\": self.language,\n",
      "            \"is_experiment\": self.is_experiment,\n",
      "        }\n",
      "\n",
      "    @property\n",
      "    def base_cov(self) -> TestCoverage:\n",
      "        return TestCoverage([cov.deserialize() for cov in self.cov_list])\n",
      "  repo/service.py#145.27\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.repo import GitRepo, SourceRepo\n",
      "\n",
      "from src.utils import gen_random_name\n",
      "from src.auth.models import CowboyUser\n",
      "from src.config import REPOS_ROOT\n",
      "from src.runner.service import run_test, RunServiceArgs\n",
      "from src.queue.core import TaskQueue\n",
      "from src.coverage.service import upsert_coverage\n",
      "from src.test_modules.service import create_all_tms\n",
      "\n",
      "from .models import RepoConfig, RepoConfigCreate\n",
      "from ..test_modules.iter_tms import iter_test_modules\n",
      "\n",
      "from pathlib import Path\n",
      "from logging import getLogger\n",
      "from fastapi import HTTPException\n",
      "\n",
      "\n",
      "logger = getLogger(__name__)\n",
      "\n",
      "\n",
      "def get(*, db_session, curr_user: CowboyUser, repo_name: str) -> RepoConfig:\n",
      "    \"\"\"Returns a repo based on the given repo name.\"\"\"\n",
      "    return (\n",
      "        db_session.query(RepoConfig)\n",
      "        .filter(RepoConfig.repo_name == repo_name, RepoConfig.user_id == curr_user.id)\n",
      "        .one_or_none()\n",
      "    )\n",
      "  repo/service.py#147.17\n",
      "----------------------------------------------------------------------\n",
      "def get_all(*, db_session) -> list[RepoConfig]:\n",
      "    \"\"\"Returns all repos.\"\"\"\n",
      "    return db_session.query(RepoConfig).all()\n",
      "\n",
      "\n",
      "def get_by_id_or_raise(\n",
      "    *, db_session, curr_user: CowboyUser, repo_id: int\n",
      ") -> RepoConfig:\n",
      "    \"\"\"Returns a repo based on the given repo id.\"\"\"\n",
      "    repo = (\n",
      "        db_session.query(RepoConfig)\n",
      "        .filter(RepoConfig.id == repo_id, RepoConfig.user_id == curr_user.id)\n",
      "        .one_or_none()\n",
      "    )\n",
      "    if not repo:\n",
      "        raise HTTPException(status_code=400, detail=f\"Repo {repo_id} not found\")\n",
      "\n",
      "    return repo\n",
      "  repo/service.py#148.36\n",
      "----------------------------------------------------------------------\n",
      "def get_experiment(*, db_session, curr_user: CowboyUser, repo_name: str) -> RepoConfig:\n",
      "    \"\"\"Returns a repo based on the given repo name.\"\"\"\n",
      "\n",
      "    return (\n",
      "        db_session.query(RepoConfig)\n",
      "        .filter(\n",
      "            RepoConfig.repo_name == repo_name,\n",
      "            RepoConfig.user_id == curr_user.id,\n",
      "            RepoConfig.is_experiment == True,\n",
      "        )\n",
      "        .one_or_none()\n",
      "    )\n",
      "\n",
      "\n",
      "def delete(*, db_session, curr_user: CowboyUser, repo_name: str) -> RepoConfig:\n",
      "    \"\"\"Deletes a repo based on the given repo name.\"\"\"\n",
      "\n",
      "    repo = get(db_session=db_session, curr_user=curr_user, repo_name=repo_name)\n",
      "    if repo:\n",
      "        db_session.delete(repo)\n",
      "        db_session.commit()\n",
      "\n",
      "        GitRepo.delete_repo(Path(repo.source_folder))\n",
      "        return repo\n",
      "\n",
      "    return None\n",
      "\n",
      "\n",
      "def clean(*, db_session, curr_user: CowboyUser, repo_name: str) -> RepoConfig:\n",
      "    \"\"\"Cleans repo branches.\"\"\"\n",
      "\n",
      "    repo = get(db_session=db_session, curr_user=curr_user, repo_name=repo_name)\n",
      "    if repo:\n",
      "        GitRepo.clean_branches(Path(repo.source_folder))\n",
      "        return repo\n",
      "\n",
      "    return None\n",
      "  repo/service.py#149.49\n",
      "----------------------------------------------------------------------\n",
      "async def create(\n",
      "    *,\n",
      "    db_session,\n",
      "    curr_user: CowboyUser,\n",
      "    repo_in: RepoConfigCreate,\n",
      "    task_queue: TaskQueue,\n",
      ") -> RepoConfig:\n",
      "    \"\"\"Creates a new repo.\"\"\"\n",
      "\n",
      "    repo_dst = None\n",
      "    try:\n",
      "        repo = RepoConfig(\n",
      "            **repo_in.dict(),\n",
      "            user_id=curr_user.id,\n",
      "        )\n",
      "\n",
      "        repo_dst = Path(REPOS_ROOT) / repo.repo_name / gen_random_name()\n",
      "        GitRepo.clone_repo(repo_dst, repo.url)\n",
      "\n",
      "        src_repo = SourceRepo(repo_dst)\n",
      "        repo.source_folder = str(repo_dst)\n",
      "        db_session.add(repo)\n",
      "        # have to commit here or because run_test depends on existing RepoConfig\n",
      "        db_session.commit()\n",
      "\n",
      "        # get base coverage for repo\n",
      "        service_args = RunServiceArgs(user_id=curr_user.id, task_queue=task_queue)\n",
      "        cov_res = await run_test(repo.repo_name, service_args)\n",
      "        upsert_coverage(\n",
      "            db_session=db_session,\n",
      "            repo_id=repo.id,\n",
      "            cov_list=cov_res.coverage.cov_list,\n",
      "        )\n",
      "\n",
      "        # create test modules\n",
      "        create_all_tms(db_session=db_session, repo_conf=repo, src_repo=src_repo)\n",
      "\n",
      "        db_session.commit()\n",
      "        return repo\n",
      "\n",
      "    except Exception as e:\n",
      "        db_session.rollback()\n",
      "        if repo:\n",
      "            delete(db_session=db_session, curr_user=curr_user, repo_name=repo.repo_name)\n",
      "\n",
      "        if repo_dst:\n",
      "            GitRepo.delete_repo(repo_dst)\n",
      "\n",
      "        logger.error(f\"Failed to create repo configuration: {e}\")\n",
      "        raise\n",
      "  repo/service.py#150.47\n",
      "----------------------------------------------------------------------\n",
      "def update(\n",
      "    *, db_session, curr_user: CowboyUser, repo_name: int, repo_in: RepoConfigCreate\n",
      ") -> RepoConfig:\n",
      "    \"\"\"Updates a repo.\"\"\"\n",
      "\n",
      "    repo = get(db_session=db_session, curr_user=curr_user, repo_name=repo_name)\n",
      "    if not repo:\n",
      "        return None\n",
      "\n",
      "    repo.update(repo_in)\n",
      "    db_session.commit()\n",
      "\n",
      "    return repo\n",
      "\n",
      "\n",
      "async def create_or_update(\n",
      "    *,\n",
      "    db_session,\n",
      "    curr_user: CowboyUser,\n",
      "    repo_in: RepoConfigCreate,\n",
      "    task_queue: TaskQueue,\n",
      ") -> RepoConfig:\n",
      "    \"\"\"Create or update a repo\"\"\"\n",
      "    repo_conf = get(\n",
      "        db_session=db_session, curr_user=curr_user, repo_name=repo_in.repo_name\n",
      "    )\n",
      "\n",
      "    if not repo_conf:\n",
      "        return await create(\n",
      "            db_session=db_session,\n",
      "            curr_user=curr_user,\n",
      "            repo_in=repo_in,\n",
      "            task_queue=task_queue,\n",
      "        )\n",
      "\n",
      "    return update(\n",
      "        db_session=db_session,\n",
      "        curr_user=curr_user,\n",
      "        repo_name=repo_in.repo_name,\n",
      "        repo_in=repo_in,\n",
      "    )\n",
      "\n",
      "\n",
      "def list(*, db_session, curr_user: CowboyUser) -> RepoConfig:\n",
      "    \"\"\"Lists all repos for a user.\"\"\"\n",
      "\n",
      "    return db_session.query(RepoConfig).filter(RepoConfig.user_id == curr_user.id).all()\n",
      "  repo/views.py#153.18\n",
      "----------------------------------------------------------------------\n",
      "@repo_router.delete(\"/repo/delete/{repo_name}\", response_model=HTTPSuccess)\n",
      "async def delete_repo(\n",
      "    repo_name: str,\n",
      "    db_session: Session = Depends(get_db),\n",
      "    current_user: CowboyUser = Depends(get_current_user),\n",
      "    task_queue: TaskQueue = Depends(get_queue),\n",
      "):\n",
      "    deleted = delete(db_session=db_session, repo_name=repo_name, curr_user=current_user)\n",
      "    if not deleted:\n",
      "        raise HTTPException(\n",
      "            status_code=400, detail=\"A repo with this name does not exists.\"\n",
      "        )\n",
      "\n",
      "    # need this to shut down the client after a repo is deleted, or else\n",
      "    # it will use old cloned_folders to execute the runner\n",
      "    args = RunServiceArgs(user_id=current_user.id, task_queue=task_queue)\n",
      "    await shutdown_client(args)\n",
      "\n",
      "    return HTTPSuccess()\n",
      "  runner/service.py#158.22\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.repo.repository import PatchFile\n",
      "from cowboy_lib.coverage import CoverageResult\n",
      "from cowboy_lib.ast.code import Function\n",
      "\n",
      "from cowboy_lib.api.runner.shared import (\n",
      "    Task,\n",
      "    TaskType,\n",
      "    RunTestTaskArgs,\n",
      "    FunctionArg,\n",
      ")\n",
      "from src.queue.service import enqueue_task_and_wait\n",
      "from src.queue.core import TaskQueue\n",
      "\n",
      "from .models import json_to_coverage_result\n",
      "\n",
      "from typing import List, Tuple\n",
      "from dataclasses import dataclass\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class RunServiceArgs:\n",
      "    user_id: int\n",
      "    task_queue: TaskQueue\n",
      "  stats/service.py#165.22\n",
      "----------------------------------------------------------------------\n",
      "from src.repo.models import RepoConfig\n",
      "from .models import RepoStats\n",
      "\n",
      "from contextlib import contextmanager\n",
      "from sqlalchemy.orm import Session\n",
      "\n",
      "\n",
      "@contextmanager\n",
      "def update_repo_stats(*, db_session: Session, repo: RepoConfig):\n",
      "    try:\n",
      "        stats = db_session.query(RepoStats).filter_by(repo_id=repo.id).one_or_none()\n",
      "        if not stats:\n",
      "            stats = RepoStats(\n",
      "                repo_id=repo.id, total_tests=0, accepted_tests=0, rejected_tests=0\n",
      "            )\n",
      "            db_session.add(stats)\n",
      "        yield stats\n",
      "\n",
      "        db_session.commit()\n",
      "    except Exception as e:\n",
      "        db_session.rollback()\n",
      "        raise e\n",
      "  src/sync_repos.py#167.17\n",
      "----------------------------------------------------------------------\n",
      "def start_sync_thread(db_session: Session, task_queue: TaskQueue):\n",
      "    def run_async_thread(loop, func, *args):\n",
      "        \"\"\"\n",
      "        Helper func to run async functions in a new thread\n",
      "        \"\"\"\n",
      "        asyncio.set_event_loop(loop)\n",
      "        loop.run_until_complete(func(*args))\n",
      "\n",
      "    threading.Thread(\n",
      "        target=run_async_thread,\n",
      "        args=(\n",
      "            asyncio.new_event_loop(),\n",
      "            check_for_changed_files,\n",
      "            db_session,\n",
      "            task_queue,\n",
      "        ),\n",
      "        daemon=True,\n",
      "    ).start()\n",
      "  src/sync_repos.py#170.35\n",
      "----------------------------------------------------------------------\n",
      "async def check_for_changed_files(\n",
      "    db_session: Session, task_queue: TaskQueue\n",
      ") -> ChangedFiles:\n",
      "    \"\"\"\n",
      "    Checks for repo update\n",
      "    \"\"\"\n",
      "    while True:\n",
      "        repos = get_all(db_session=db_session)\n",
      "        for repo in repos:\n",
      "            git_repo = GitRepo(Path(repo.source_folder))\n",
      "            user_token = get_user_token(db_session=db_session, user_id=repo.user_id)\n",
      "            api_client = APIClient(API_ENDPOINT, user_token)\n",
      "\n",
      "            commit = git_repo.diff_remote()\n",
      "            if commit:\n",
      "                for diff in commit.diffs:\n",
      "                    if diff.attrs.mode == DiffMode.MODIFIED:\n",
      "                        modified_file = diff.attrs.a_path\n",
      "                        impacted_tm = (\n",
      "                            testfile_to_tm(db_session, repo.id, modified_file)\n",
      "                            if is_test_file(modified_file)\n",
      "                            else srcfile_to_tm(db_session, repo.id, modified_file)\n",
      "                        )\n",
      "                        log.info(f\"Impacted tm: {impacted_tm.name}\")\n",
      "\n",
      "                        if not impacted_tm:\n",
      "                            # TODO: really bad, because it implies that we are\n",
      "                            # missing some kind of update to the repo\n",
      "                            return\n",
      "\n",
      "                        await api_client.build_mapping(\n",
      "                            repo.repo_name, \"module\", [impacted_tm.name]\n",
      "                        )\n",
      "\n",
      "        await asyncio.sleep(10)\n",
      "  test_gen/augment.py#186.59\n",
      "----------------------------------------------------------------------\n",
      "async def augment_test(\n",
      "    *,\n",
      "    db_session: Session,\n",
      "    task_queue: TaskQueue,\n",
      "    repo: RepoConfig,\n",
      "    tm_model: TestModuleModel,\n",
      "    curr_user: CowboyUser,\n",
      "    session_id: str\n",
      ") -> List[AugmentTestResult]:\n",
      "    \"\"\"\n",
      "    Generate test cases for the given test module using the specified strategy and evaluator\n",
      "    \"\"\"\n",
      "    src_repo = SourceRepo(Path(repo.source_folder))\n",
      "    git_repo = GitRepo(Path(repo.source_folder), remote=repo.remote, main=repo.main)\n",
      "    tm = tm_model.serialize(src_repo)\n",
      "    run_args = RunServiceArgs(user_id=curr_user.id, task_queue=task_queue)\n",
      "\n",
      "    base_cov = repo.base_cov\n",
      "    composer = Composer(\n",
      "        repo_name=repo.repo_name,\n",
      "        strat=\"WITH_CTXT\",\n",
      "        evaluator=\"ADDITIVE\",\n",
      "        src_repo=src_repo,\n",
      "        test_input=tm,\n",
      "        run_args=run_args,\n",
      "        base_cov=base_cov,\n",
      "        api_key=retrieve_oai_key(curr_user.id),\n",
      "    )\n",
      "\n",
      "    improved_tests, failed_tests, no_improve_tests = await composer.generate_test(\n",
      "        n_times=AUGMENT_ROUNDS\n",
      "    )\n",
      "\n",
      "    # write all improved test to source file and check out merge on repo\n",
      "    # serialize tm first\n",
      "    test_results = []\n",
      "    test_file = tm.test_file\n",
      "    for improved, cov in improved_tests:\n",
      "        test_result = create_test_result(\n",
      "            db_session=db_session,\n",
      "            repo_id=repo.id,\n",
      "            name=improved.name,\n",
      "            test_case=improved.to_code(),\n",
      "            cov_list=cov.cov_list,\n",
      "            tm_id=tm_model.id,\n",
      "            commit_hash=git_repo.get_curr_commit(),\n",
      "            testfile=str(test_file.path),\n",
      "            session_id=session_id,\n",
      "            classname=None,\n",
      "        )\n",
      "        test_results.append(test_result)\n",
      "\n",
      "    # update repo stats\n",
      "    with update_repo_stats(db_session=db_session, repo=repo) as repo_stats:\n",
      "        repo_stats.total_tests += (\n",
      "            len(improved_tests) + len(failed_tests) + len(no_improve_tests)\n",
      "        )\n",
      "\n",
      "    return test_results\n",
      "  test_modules/service.py#231.17\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.repo import SourceRepo\n",
      "\n",
      "from src.repo.models import RepoConfig\n",
      "from src.ast.service import create_node\n",
      "\n",
      "from .iter_tms import iter_test_modules\n",
      "from .models import TestModuleModel, TestModule\n",
      "\n",
      "from sqlalchemy.orm import Session\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def create_all_tms(*, db_session: Session, repo_conf: RepoConfig, src_repo: SourceRepo):\n",
      "    \"\"\"Create all test modules for a repo.\"\"\"\n",
      "    test_modules = iter_test_modules(src_repo)\n",
      "\n",
      "    for tm in test_modules:\n",
      "        create_tm(db_session=db_session, repo_id=repo_conf.id, tm=tm)\n",
      "  src/utils.py#239.45\n",
      "----------------------------------------------------------------------\n",
      "import functools\n",
      "import random\n",
      "import string\n",
      "import uuid\n",
      "import time\n",
      "import functools\n",
      "from src.logger import testgen_logger\n",
      "\n",
      "\n",
      "# nested level get() function\n",
      "def resolve_attr(obj, attr, default=None):\n",
      "    \"\"\"Attempts to access attr via dotted notation, returns none if attr does not exist.\"\"\"\n",
      "    try:\n",
      "        return functools.reduce(getattr, attr.split(\".\"), obj)\n",
      "    except AttributeError:\n",
      "        return default\n",
      "\n",
      "\n",
      "def gen_random_name():\n",
      "    \"\"\"\n",
      "    Generates a random name using ASCII, 8 characters in length\n",
      "    \"\"\"\n",
      "\n",
      "    return \"\".join(random.choices(string.ascii_lowercase, k=8))\n",
      "\n",
      "\n",
      "def generate_id():\n",
      "    \"\"\"\n",
      "    Generates a random UUID\n",
      "    \"\"\"\n",
      "    return str(uuid.uuid4())\n",
      "\n",
      "\n",
      "def async_timed(func):\n",
      "    @functools.wraps(func)\n",
      "    async def wrapper(*args, **kwargs):\n",
      "        start_time = time.time()\n",
      "        result = await func(*args, **kwargs)\n",
      "        end_time = time.time()\n",
      "        testgen_logger.info(\n",
      "            f\"[PARALLEL] Function {func.__name__} took {end_time - start_time:.4f} seconds\"\n",
      "        )\n",
      "        return result\n",
      "\n",
      "    return wrapper\n",
      "Cluster 3\n",
      "  ast/code.py#6.86\n",
      "----------------------------------------------------------------------\n",
      "from typing import List, Optional, Tuple, NewType, Union\n",
      "from dataclasses import dataclass, field\n",
      "from enum import Enum\n",
      "\n",
      "import ast\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class Argument:\n",
      "    name: str\n",
      "    type: Optional[str]\n",
      "\n",
      "    def __str__(self):\n",
      "        name = self.name\n",
      "        type = f\"{':' + self.type if self.type else ''}\"\n",
      "        return name + type\n",
      "\n",
      "\n",
      "class ASTNode:\n",
      "    def __init__(\n",
      "        self,\n",
      "        name: str,\n",
      "        range: Tuple[int, int],\n",
      "        scope: Optional[\"ASTNode\"],\n",
      "        decorators: List[\"Decorator\"],\n",
      "        lines: List[str],\n",
      "        ast_node: Optional[ast.AST],\n",
      "        is_test: bool = False,\n",
      "        node_type: Optional[\"NodeType\"] = None,\n",
      "    ):\n",
      "        # need to turn on mypy for this shit ...\n",
      "        if decorators:\n",
      "            assert isinstance(decorators[0], Decorator)\n",
      "        else:\n",
      "            assert isinstance(decorators, list) and len(decorators) == 0\n",
      "\n",
      "        self._name = name\n",
      "        # REFACTOR-AST: create a lang specific AST node class to account for decorators?\n",
      "        # ie. PyAST/GolangAST\n",
      "        self.decorators = decorators\n",
      "        self.range = self._set_range(range)\n",
      "        self.lines = [l.rstrip() for l in lines]\n",
      "        self.is_test = is_test\n",
      "        self.scope = scope\n",
      "        self.ast_node = ast_node\n",
      "        self.node_type = self.get_node_type()\n",
      "\n",
      "    def get_node_type(self):\n",
      "        return NodeType(self.__class__.__name__)\n",
      "\n",
      "    def is_ast(self, other_ast: ast.AST) -> bool:\n",
      "        \"\"\"\n",
      "        Checks if self matches another ast.AST node\n",
      "        \"\"\"\n",
      "        return self.ast_node == other_ast\n",
      "\n",
      "    def __eq__(self, other: \"ASTNode\"):\n",
      "        return self.name + str(self.range) == other.name + str(other.range)\n",
      "\n",
      "    def __hash__(self):\n",
      "        return sum([ord(c) for c in self.name + str(self.range)])\n",
      "\n",
      "    def _set_range(self, range) -> Tuple[int, int]:\n",
      "        start = self.decorators[0].range[0] if self.decorators else range[0]\n",
      "        end = range[1]\n",
      "        return (start, end)\n",
      "\n",
      "    def set_is_test(self, is_test: bool):\n",
      "        self.is_test = is_test\n",
      "\n",
      "    def to_code(self):\n",
      "        repr = \"\"\n",
      "        for dec in self.decorators:\n",
      "            repr += dec.to_code()\n",
      "\n",
      "        # newline if we have decorators\n",
      "        repr += \"\\n\" if repr else \"\"\n",
      "        repr += \"\\n\".join([l.rstrip() for l in self.lines])\n",
      "        return repr\n",
      "\n",
      "    @property\n",
      "    def type(self) -> \"NodeType\":\n",
      "        return NodeType(self.__class__.__name__)\n",
      "\n",
      "    @property\n",
      "    def name(self):\n",
      "        raise NotImplementedError\n",
      "  cowboy_lib/coverage.py#21.38\n",
      "----------------------------------------------------------------------\n",
      "class Coverage:\n",
      "\n",
      "    def print_lines(self, line_type: str = \"covered\"):\n",
      "        lines_dict = (\n",
      "            self._covered_lines_dict\n",
      "            if line_type == \"covered\"\n",
      "            else self._miss_lines_dict\n",
      "        )\n",
      "\n",
      "        repr = \"\"\n",
      "        repr += f\"{line_type} lines in :: {self.filename}\\n\"\n",
      "        for k, v in lines_dict.items():\n",
      "            repr += f\"{k}: {v}\\n\"\n",
      "\n",
      "        return repr\n",
      "\n",
      "    def get_contiguous_lines(self) -> Iterable[List[Tuple[int, str]]]:\n",
      "        \"\"\"\n",
      "        Returns a list of contiguous line groups\n",
      "        \"\"\"\n",
      "        from itertools import groupby\n",
      "\n",
      "        for k, g in groupby(\n",
      "            enumerate(self._covered_lines_dict.items()), lambda ix: ix[1][0] - ix[0]\n",
      "        ):\n",
      "            yield [x for _, x in g]\n",
      "\n",
      "    def serialize(self):\n",
      "        return {\n",
      "            \"filename\": self.filename,\n",
      "            \"covered_lines\": self.covered_lines,\n",
      "            \"missing_lines\": self.missing_lines,\n",
      "        }\n",
      "\n",
      "    @classmethod\n",
      "    def deserialize(self, data) -> \"Coverage\":\n",
      "        return Coverage(data[\"filename\"], data[\"covered_lines\"], data[\"missing_lines\"])\n",
      "\n",
      "\n",
      "class NoCoverageDB(Exception):\n",
      "    pass\n",
      "  repo/source_repo.py#69.38\n",
      "----------------------------------------------------------------------\n",
      "class SourceRepo:\n",
      "\n",
      "    def get_test_funcs(self) -> List[Function]:\n",
      "        return reduce(\n",
      "            lambda x, y: x + y,\n",
      "            [test_file.test_funcs() for test_file in self.test_files],\n",
      "            [],\n",
      "        )\n",
      "\n",
      "    def get_test_classes(self) -> List[Class]:\n",
      "        classes = reduce(\n",
      "            lambda x, y: x + y,\n",
      "            [test_file.test_classes() for test_file in self.test_files],\n",
      "            [],\n",
      "        )\n",
      "        return classes\n",
      "\n",
      "    def iter_tests(self) -> Iterator[Tuple[TestFile, Class]]:\n",
      "        for test_file in self.test_files:\n",
      "            for test_class in test_file.test_classes():\n",
      "                yield test_file, test_class\n",
      "\n",
      "    def find_file(self, file_path: str) -> Optional[SourceFile]:\n",
      "        \"\"\"\n",
      "        Returns the file object\n",
      "        \"\"\"\n",
      "        for file in self.source_files:\n",
      "            # NOTE: need path here to deal with consistent / and \\ in windows\n",
      "            if Path(file.path) == Path(file_path):\n",
      "                return file\n",
      "\n",
      "    def write_file(self, file_path: str):\n",
      "        \"\"\"\n",
      "        Writes the content of a SourceFile to its original file on disk.\n",
      "        Note that this API is implemented on SourceRepo because we want\n",
      "        to control all I/O interactions through this class\n",
      "        \"\"\"\n",
      "        src_file = self.find_file(file_path)\n",
      "        with open(self.repo_path / file_path, \"w\") as f:\n",
      "            f.write(src_file.to_code())\n",
      "  test_modules/target_code.py#71.42\n",
      "----------------------------------------------------------------------\n",
      "from dataclasses import dataclass\n",
      "\n",
      "from typing import List, Optional, TYPE_CHECKING, Tuple\n",
      "from pathlib import Path\n",
      "\n",
      "from cowboy_lib.ast.code import ASTNode\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class TargetCode:\n",
      "    \"\"\"\n",
      "    A chunk of code that is covered by the lines in a TestModule\n",
      "    \"\"\"\n",
      "\n",
      "    range: Tuple[int, int]\n",
      "    lines: List[str]\n",
      "    filepath: Path\n",
      "    func_scope: Optional[ASTNode]\n",
      "    class_scope: Optional[ASTNode]\n",
      "\n",
      "    def base_path(self) -> Path:\n",
      "        \"\"\"\n",
      "        Returns the base path relative to the repo directory\n",
      "        \"\"\"\n",
      "        return Path(*self.filepath.parts[2:])\n",
      "\n",
      "    def __post_init__(self):\n",
      "        if not isinstance(self.filepath, Path):\n",
      "            self.filepath = Path(self.filepath)\n",
      "\n",
      "    def __eq__(self, other: \"TargetCode\"):\n",
      "        return self.filepath == other.filepath and self.range == other.range\n",
      "\n",
      "    def __hash__(self):\n",
      "        return hash((self.filepath, self.range))\n",
      "\n",
      "    def to_lines(self):\n",
      "        repr = \"\"\n",
      "        for i, line in zip(range(self.range[0], self.range[1] + 1), self.lines):\n",
      "            repr += f\"{i}. {line}\\n\"\n",
      "\n",
      "        return repr\n",
      "  test_modules/test_module.py#75.35\n",
      "----------------------------------------------------------------------\n",
      "class TestModule:\n",
      "\n",
      "    def set_chunks(\n",
      "        self,\n",
      "        changed_coverage: List[Coverage],\n",
      "        source_repo: \"SourceRepo\",\n",
      "        base_path: Path = None,\n",
      "    ):\n",
      "        \"\"\"\n",
      "        Gets the missing/covered lines of each of the coverage differences\n",
      "        \"\"\"\n",
      "        self.chunks = []\n",
      "        for cov in changed_coverage:\n",
      "            if cov.filename == \"TOTAL\":\n",
      "                raise Exception(\"TOTAL COVERAGE FILE FOUND\")\n",
      "\n",
      "            cov.read_line_contents(base_path)\n",
      "            for l_group in cov.get_contiguous_lines():\n",
      "                start = l_group[0][0]\n",
      "                end = l_group[-1][0]\n",
      "                range = (start, end)\n",
      "\n",
      "                src_file = source_repo.find_file(cov.filename)\n",
      "                func, cls = src_file.map_line_to_node(start, end)\n",
      "\n",
      "                lines = [g[1] for g in l_group]\n",
      "\n",
      "                print(\"Setting chunk with filepath: \", str(cov.filename))\n",
      "\n",
      "                chunk = TargetCode(\n",
      "                    range=range,\n",
      "                    lines=lines,\n",
      "                    # could also just move the logic into TestModuleMixin\n",
      "                    filepath=str(cov.filename),\n",
      "                    func_scope=func if func else \"\",\n",
      "                    class_scope=cls if cls else \"\",\n",
      "                )\n",
      "                self.chunks.append(chunk)\n",
      "  ast/models.py#87.56\n",
      "----------------------------------------------------------------------\n",
      "from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, Boolean\n",
      "\n",
      "from cowboy_lib.ast.code import ASTNode\n",
      "from cowboy_lib.repo.source_repo import SourceRepo\n",
      "from src.database.core import Base\n",
      "\n",
      "\n",
      "class NodeModel(Base):\n",
      "    \"\"\"\n",
      "    An AST node, either a class or a function, that holds a single or a group of unit tests\n",
      "    \"\"\"\n",
      "\n",
      "    __tablename__ = \"nodes\"\n",
      "    id = Column(Integer, primary_key=True)\n",
      "    name = Column(String)\n",
      "    node_type = Column(String)\n",
      "    testfilepath = Column(String)\n",
      "\n",
      "    # start_line = Column(Integer)\n",
      "    # end_line = Column(Integer)\n",
      "    # lines = Column(String)\n",
      "    # is_test = Column(Boolean)\n",
      "    # scope_id = Column(Integer, ForeignKey(\"nodes.id\"))\n",
      "    # children = relationship(\n",
      "    #     \"NodeModel\",\n",
      "    #     backref=backref(\"parent\", remote_side=[id]),\n",
      "    #     cascade=\"all, delete-orphan\",\n",
      "    # )\n",
      "\n",
      "    # # decorators = Column\n",
      "\n",
      "    repo_id = Column(Integer, ForeignKey(\"repo_config.id\", ondelete=\"CASCADE\"))\n",
      "    # Node is either related to test_modules or target_code\n",
      "    test_module_id = Column(\n",
      "        Integer,\n",
      "        ForeignKey(\"test_modules.id\", ondelete=\"CASCADE\"),\n",
      "        nullable=True,\n",
      "    )\n",
      "    target_code_id = Column(\n",
      "        Integer,\n",
      "        ForeignKey(\"target_code.id\", ondelete=\"CASCADE\"),\n",
      "        nullable=True,\n",
      "    )\n",
      "\n",
      "    # chunks = relationship(\"TargetCodeModel\", backref=\"nodes\")\n",
      "\n",
      "    def to_astnode(self, source_repo: SourceRepo):\n",
      "        node = source_repo.find_node(self.name, self.testfilepath, self.node_type)\n",
      "        return node\n",
      "\n",
      "    @classmethod\n",
      "    def from_astnode(cls, node: ASTNode) -> \"NodeModel\":\n",
      "        return cls(\n",
      "            name=node.name,\n",
      "            node_type=node.node_type,\n",
      "        )\n",
      "  ast/service.py#88.43\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.ast.code import ASTNode\n",
      "from cowboy_lib.test_modules.test_module import TestModule\n",
      "\n",
      "from src.test_modules.models import TestModuleModel\n",
      "\n",
      "from sqlalchemy.orm import Session\n",
      "from .models import NodeModel\n",
      "\n",
      "\n",
      "def get_node(\n",
      "    *, db_session: Session, node_name: str, repo_id: int, node_type: str, filepath: str\n",
      "):\n",
      "    return (\n",
      "        db_session.query(NodeModel)\n",
      "        .filter(\n",
      "            NodeModel.name == node_name,\n",
      "            NodeModel.repo_id == repo_id,\n",
      "            NodeModel.node_type == node_type,\n",
      "            NodeModel.testfilepath == filepath,\n",
      "        )\n",
      "        .one_or_none()\n",
      "    )\n",
      "\n",
      "\n",
      "def create_node(\n",
      "    *,\n",
      "    db_session: Session,\n",
      "    node: ASTNode,\n",
      "    repo_id: int,\n",
      "    filepath: str,\n",
      "    test_module_id: str = None,\n",
      "):\n",
      "    node = NodeModel(\n",
      "        name=node.name,\n",
      "        node_type=node.node_type.value,\n",
      "        repo_id=repo_id,\n",
      "        test_module_id=test_module_id,\n",
      "        testfilepath=filepath,\n",
      "    )\n",
      "\n",
      "    db_session.add(node)\n",
      "    db_session.commit()\n",
      "\n",
      "    return node\n",
      "  ast/service.py#89.32\n",
      "----------------------------------------------------------------------\n",
      "def create_or_update_node(\n",
      "    *, db_session: Session, repo_id: str, node: ASTNode, filepath: str\n",
      "):\n",
      "    old_node = get_node(\n",
      "        db_session=db_session,\n",
      "        node_name=node.name,\n",
      "        repo_id=repo_id,\n",
      "        node_type=node.node_type.value,\n",
      "        filepath=filepath,\n",
      "    )\n",
      "\n",
      "    if old_node:\n",
      "        # NOTE: there is actually no point in updating node right now\n",
      "        # because none of the node attributes should change ..\n",
      "        print(\"Node exists: \", node.name)\n",
      "        # node_model = (\n",
      "        #     db_session.query(NodeModel)\n",
      "        #     .filter(\n",
      "        #         NodeModel.name == node.name\n",
      "        #         and NodeModel.repo_id == repo_id\n",
      "        #         and NodeModel.node_type == node.node_type\n",
      "        #         and NodeModel.testfilepath == filepath\n",
      "        #     )\n",
      "        #     .update(node)\n",
      "        # )\n",
      "        return old_node\n",
      "    else:\n",
      "        node_model = create_node(\n",
      "            db_session=db_session, node=node, repo_id=repo_id, filepath=filepath\n",
      "        )\n",
      "\n",
      "    return node_model\n",
      "  coverage/models.py#113.33\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.coverage import Coverage, TestCoverage\n",
      "\n",
      "from sqlalchemy import Column, Integer, String, ForeignKey\n",
      "from sqlalchemy.orm import relationship\n",
      "from src.database.core import Base\n",
      "from typing import List\n",
      "\n",
      "\n",
      "class CoverageModel(Base):\n",
      "    __tablename__ = \"coverage\"\n",
      "\n",
      "    id = Column(Integer, primary_key=True)\n",
      "    filename = Column(String, nullable=False)\n",
      "    covered_lines = Column(String, nullable=False)\n",
      "    missing_lines = Column(String, nullable=False)\n",
      "\n",
      "    stmts = Column(Integer, nullable=False)\n",
      "    misses = Column(Integer, nullable=False)\n",
      "    covered = Column(Integer, nullable=False)\n",
      "\n",
      "    # test_coverage_id = Column(Integer, ForeignKey(\"test_coverage.id\"))\n",
      "    target_code_list = relationship(\n",
      "        \"TargetCodeModel\", back_populates=\"coverage\", cascade=\"all, delete-orphan\"\n",
      "    )\n",
      "    repo_id = Column(Integer, ForeignKey(\"repo_config.id\"))\n",
      "    test_result_id = Column(Integer, ForeignKey(\"augment_test_results.id\"))\n",
      "\n",
      "    def deserialize(self) -> Coverage:\n",
      "        return Coverage(\n",
      "            filename=self.filename,\n",
      "            covered_lines=[int(l) for l in self.covered_lines.split(\",\") if l],\n",
      "            missing_lines=[int(l) for l in self.missing_lines.split(\",\") if l],\n",
      "        )\n",
      "  coverage/service.py#115.20\n",
      "----------------------------------------------------------------------\n",
      "def get_cov_by_filename(\n",
      "    *, db_session: Session, repo_id: int, filename: str\n",
      ") -> CoverageModel:\n",
      "    \"\"\"Get a coverage model by filename.\"\"\"\n",
      "\n",
      "    return (\n",
      "        db_session.query(CoverageModel)\n",
      "        .filter(CoverageModel.filename == filename, CoverageModel.repo_id == repo_id)\n",
      "        .one_or_none()\n",
      "    )\n",
      "\n",
      "\n",
      "def get_cov_by_id(*, db_session: Session, repo_id: int, id: int) -> CoverageModel:\n",
      "    \"\"\"Get a coverage model by id.\"\"\"\n",
      "\n",
      "    return (\n",
      "        db_session.query(CoverageModel)\n",
      "        .filter(CoverageModel.id == id, CoverageModel.repo_id == repo_id)\n",
      "        .one_or_none()\n",
      "    )\n",
      "  coverage/stats.py#116.27\n",
      "----------------------------------------------------------------------\n",
      "from src.coverage.models import CoverageModel\n",
      "from cowboy_lib.coverage import Coverage\n",
      "\n",
      "from src.test_modules.models import TestModuleModel, TestModule\n",
      "\n",
      "from pathlib import Path\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def get_coverage_stats(tm: TestModule, cov: Coverage):\n",
      "    \"\"\"\n",
      "    Calculate stats on what % of coverage is our baseline'd TestModule covering\n",
      "    \"\"\"\n",
      "    total_covered = cov.covered\n",
      "    tgt_covered = 0\n",
      "    missing = cov.misses\n",
      "\n",
      "    for chunk in tm.chunks:\n",
      "        if Path(chunk.filepath) == cov.filename:\n",
      "            tgt_covered += len(chunk.lines)\n",
      "\n",
      "    score = get_score(tgt_covered, total_covered, missing)\n",
      "    return score\n",
      "\n",
      "\n",
      "def get_score(tgt_covered, total_covered, missing):\n",
      "    return tgt_covered + missing / total_covered if total_covered else 0\n",
      "  src/sync_repos.py#168.25\n",
      "----------------------------------------------------------------------\n",
      "def testfile_to_tm(db: Session, repo_id: str, file: str) -> TestModuleModel:\n",
      "    \"\"\"\n",
      "    Maps the file back to the test_module. This is a one-to-one mapping\n",
      "    \"\"\"\n",
      "    tms = get_all_tms(db_session=db, repo_id=repo_id)\n",
      "    for tm in tms:\n",
      "        if tm.testfilepath == file:\n",
      "            return tm\n",
      "\n",
      "    return None\n",
      "\n",
      "\n",
      "def srcfile_to_tm(db: Session, repo_id: str, file: str) -> TestModuleModel:\n",
      "    \"\"\"\n",
      "    Maps the src file back to test_module. This is n-to-one mapping\n",
      "    \"\"\"\n",
      "    tms = get_all_tms(db_session=db, repo_id=repo_id)\n",
      "    for tm in tms:\n",
      "        if file in tm.get_covered_files():\n",
      "            return tm\n",
      "\n",
      "    return None\n",
      "\n",
      "\n",
      "def is_test_file(path: str):\n",
      "    return Path(path).name.startswith(\"test_\")\n",
      "  target_code/models.py#171.90\n",
      "----------------------------------------------------------------------\n",
      "from sqlalchemy import Column, Integer, String, DateTime, ForeignKey\n",
      "from sqlalchemy.orm import relationship\n",
      "from pydantic import BaseModel\n",
      "from pathlib import Path\n",
      "from typing import List\n",
      "\n",
      "from cowboy_lib.test_modules.test_module import TestModule\n",
      "from cowboy_lib.test_modules.target_code import TargetCode\n",
      "from cowboy_lib.repo.source_repo import SourceRepo\n",
      "from src.database.core import Base\n",
      "from src.ast.models import NodeModel\n",
      "\n",
      "\n",
      "class TargetCodeModel(Base):\n",
      "    \"\"\"\n",
      "    A chunk of code that is covered by the lines in a TestModule\n",
      "    \"\"\"\n",
      "\n",
      "    __tablename__ = \"target_code\"\n",
      "    id = Column(Integer, primary_key=True)\n",
      "    start = Column(Integer)\n",
      "    end = Column(Integer)\n",
      "    lines = Column(String)\n",
      "    filepath = Column(String)\n",
      "\n",
      "    func_scope = relationship(\n",
      "        \"NodeModel\",\n",
      "        foreign_keys=[NodeModel.target_code_id],\n",
      "        cascade=\"all, delete\",\n",
      "        uselist=False,\n",
      "        single_parent=True,\n",
      "    )\n",
      "    class_scope = relationship(\n",
      "        \"NodeModel\",\n",
      "        foreign_keys=[NodeModel.target_code_id],\n",
      "        cascade=\"all, delete\",\n",
      "        uselist=False,\n",
      "        single_parent=True,\n",
      "    )\n",
      "    test_module_id = Column(Integer, ForeignKey(\"test_modules.id\", ondelete=\"CASCADE\"))\n",
      "    coverage_id = Column(Integer, ForeignKey(\"coverage.id\", ondelete=\"CASCADE\"))\n",
      "    coverage = relationship(\"CoverageModel\")\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        start,\n",
      "        end,\n",
      "        lines,\n",
      "        filepath,\n",
      "        func_scope,\n",
      "        class_scope,\n",
      "        test_module_id,\n",
      "        coverage_id,\n",
      "    ):\n",
      "        self.start = start\n",
      "        self.end = end\n",
      "        self.lines = \"\\n\".join(lines)\n",
      "        self.filepath = str(filepath)\n",
      "        self.func_scope = func_scope\n",
      "        self.class_scope = class_scope\n",
      "        self.test_module_id = test_module_id\n",
      "        self.coverage_id = coverage_id\n",
      "\n",
      "    def get_lines(self) -> List[str]:\n",
      "        return self.lines.split(\"\\n\")\n",
      "\n",
      "    def to_str(self) -> str:\n",
      "        repr = \"\"\n",
      "        repr += f\"Chunk: {self.filepath}\\n\"\n",
      "        repr += self.lines\n",
      "\n",
      "        return repr\n",
      "\n",
      "    def serialize(self, src_repo: SourceRepo):\n",
      "        return TargetCode(\n",
      "            range=(self.start, self.end),\n",
      "            lines=self.get_lines(),\n",
      "            filepath=Path(self.filepath),\n",
      "            func_scope=(\n",
      "                self.func_scope.to_astnode(src_repo) if self.func_scope else None\n",
      "            ),\n",
      "            class_scope=(\n",
      "                self.class_scope.to_astnode(src_repo) if self.class_scope else None\n",
      "            ),\n",
      "        )\n",
      "\n",
      "\n",
      "class TgtCodeDeleteRequest(BaseModel):\n",
      "    repo_name: str\n",
      "    tm_name: str\n",
      "  target_code/service.py#172.49\n",
      "----------------------------------------------------------------------\n",
      "from src.ast.models import NodeModel\n",
      "from src.target_code.models import TargetCode, TargetCodeModel\n",
      "from src.test_modules.models import TestModuleModel\n",
      "from src.coverage.models import CoverageModel\n",
      "\n",
      "from sqlalchemy.orm import Session\n",
      "\n",
      "\n",
      "def create_target_code(\n",
      "    db_session: Session,\n",
      "    tm_model: TestModuleModel,\n",
      "    chunk: TargetCode,\n",
      "    cov_model: CoverageModel,\n",
      "    func_scope: NodeModel = None,\n",
      "    class_scope: NodeModel = None,\n",
      "):\n",
      "    \"\"\"Create a target code chunk for a test module.\"\"\"\n",
      "\n",
      "    print(\"Creating tgtcode: \", tm_model.id, tm_model.name)\n",
      "\n",
      "    target_code = TargetCodeModel(\n",
      "        lines=chunk.lines,\n",
      "        start=chunk.range[0],\n",
      "        end=chunk.range[1],\n",
      "        filepath=chunk.filepath,\n",
      "        func_scope=func_scope,\n",
      "        class_scope=class_scope,\n",
      "        test_module_id=tm_model.id,\n",
      "        coverage_id=cov_model.id,\n",
      "    )\n",
      "\n",
      "    db_session.add(target_code)\n",
      "    db_session.commit()\n",
      "\n",
      "    return target_code\n",
      "\n",
      "\n",
      "def delete_target_code(db_session: Session, tm_id: int):\n",
      "    \"\"\"Delete all target code for a test module.\"\"\"\n",
      "\n",
      "    deleted = (\n",
      "        db_session.query(TargetCodeModel)\n",
      "        .filter(TargetCodeModel.test_module_id == tm_id)\n",
      "        .delete()\n",
      "    )\n",
      "\n",
      "    db_session.commit()\n",
      "\n",
      "    return deleted\n",
      "  tasks/create_tgt_coverage.py#176.47\n",
      "----------------------------------------------------------------------\n",
      "def create_tgt_code_models(\n",
      "    tgt_code_chunks: List[TargetCode],\n",
      "    db_session: Session,\n",
      "    repo_id: int,\n",
      "    tm_model: TestModuleModel,\n",
      ") -> List[TargetCodeModel]:\n",
      "    \"\"\"\n",
      "    Create target code models\n",
      "    \"\"\"\n",
      "    target_chunks = []\n",
      "    for tgt in tgt_code_chunks:\n",
      "        func_scope = (\n",
      "            create_or_update_node(\n",
      "                db_session=db_session,\n",
      "                node=tgt.func_scope,\n",
      "                repo_id=repo_id,\n",
      "                filepath=str(tgt.filepath),\n",
      "            )\n",
      "            if tgt.func_scope\n",
      "            else None\n",
      "        )\n",
      "        class_scope = (\n",
      "            create_or_update_node(\n",
      "                db_session=db_session,\n",
      "                node=tgt.class_scope,\n",
      "                repo_id=repo_id,\n",
      "                filepath=str(tgt.filepath),\n",
      "            )\n",
      "            if tgt.class_scope\n",
      "            else None\n",
      "        )\n",
      "\n",
      "        target_chunks.append(\n",
      "            create_target_code(\n",
      "                db_session=db_session,\n",
      "                tm_model=tm_model,\n",
      "                chunk=tgt,\n",
      "                cov_model=get_cov_by_filename(\n",
      "                    db_session=db_session,\n",
      "                    repo_id=repo_id,\n",
      "                    filename=str(tgt.filepath),\n",
      "                ),\n",
      "                func_scope=func_scope,\n",
      "                class_scope=class_scope,\n",
      "            )\n",
      "        )\n",
      "\n",
      "    return target_chunks\n",
      "  augment_test/base_strat.py#187.37\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.repo.source_repo import SourceRepo\n",
      "\n",
      "from abc import ABC, abstractmethod\n",
      "from pathlib import Path\n",
      "from dataclasses import dataclass\n",
      "\n",
      "from src.runner.service import RunServiceArgs\n",
      "\n",
      "\n",
      "@dataclass\n",
      "class TestCaseInput(ABC):\n",
      "\n",
      "    @property\n",
      "    @abstractmethod\n",
      "    def path(self) -> Path:\n",
      "        raise NotImplementedError\n",
      "\n",
      "\n",
      "class BaseStrategy(ABC):\n",
      "    def __init__(self, src_repo: SourceRepo, test_input: TestCaseInput):\n",
      "        self.src_repo = src_repo\n",
      "        self.test_input = test_input\n",
      "\n",
      "    @abstractmethod\n",
      "    def build_prompt(self) -> str:\n",
      "        \"\"\"\n",
      "        Builds the base prompt according to the strategy\n",
      "        \"\"\"\n",
      "\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def parse_llm_res(self):\n",
      "        \"\"\"\n",
      "        Parses the LLM response to get the generated code\n",
      "        \"\"\"\n",
      "        raise NotImplementedError\n",
      "  test_modules/models.py#229.67\n",
      "----------------------------------------------------------------------\n",
      "from sqlalchemy import Column, Integer, String, DateTime, ForeignKey, Boolean\n",
      "from sqlalchemy.orm import relationship\n",
      "from pathlib import Path\n",
      "from typing import List, Optional\n",
      "from pydantic import BaseModel\n",
      "\n",
      "from cowboy_lib.test_modules.test_module import TestModule\n",
      "from cowboy_lib.repo.source_repo import SourceRepo\n",
      "\n",
      "from src.database.core import Base\n",
      "from src.ast.models import NodeModel\n",
      "from src.target_code.models import TargetCodeModel\n",
      "from src.test_gen.models import TMSelectModeBase, AugmentTestResult\n",
      "\n",
      "\n",
      "class IncompatibleCommit(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class TestModuleModel(Base):\n",
      "    __tablename__ = \"test_modules\"\n",
      "    id = Column(Integer, primary_key=True)\n",
      "    name = Column(String)\n",
      "    testfilepath = Column(String)\n",
      "    commit_sha = Column(String)\n",
      "    experiment_id = Column(String, nullable=True)\n",
      "    # use this flag to track test_modules that have already gone through\n",
      "    # auto-test augmentation\n",
      "    auto_gen = Column(Boolean, default=False)\n",
      "\n",
      "    repo_id = Column(Integer, ForeignKey(\"repo_config.id\"))\n",
      "    nodes = relationship(\n",
      "        \"NodeModel\",\n",
      "        backref=\"test_module\",\n",
      "        foreign_keys=[NodeModel.test_module_id],\n",
      "        cascade=\"all, delete-orphan\",\n",
      "    )\n",
      "    target_chunks = relationship(\n",
      "        \"TargetCodeModel\",\n",
      "        backref=\"test_module\",\n",
      "        foreign_keys=[TargetCodeModel.test_module_id],\n",
      "        cascade=\"all, delete-orphan\",\n",
      "    )\n",
      "    test_results = relationship(\n",
      "        \"AugmentTestResult\",\n",
      "        backref=\"test_module\",\n",
      "        foreign_keys=[AugmentTestResult.test_module_id],\n",
      "        cascade=\"all, delete-orphan\",\n",
      "    )\n",
      "\n",
      "    def serialize(self, src_repo: SourceRepo) -> TestModule:\n",
      "        \"\"\"\n",
      "        Convert model back to TestModule\n",
      "        \"\"\"\n",
      "        return TestModule(\n",
      "            test_file=src_repo.find_file(Path(self.testfilepath)),\n",
      "            commit_sha=self.commit_sha,\n",
      "            nodes=[NodeModel.to_astnode(n, src_repo) for n in self.nodes],\n",
      "            chunks=[c.serialize(src_repo) for c in self.target_chunks],\n",
      "        )\n",
      "\n",
      "    def get_covered_files(self) -> List[str]:\n",
      "        \"\"\"\n",
      "        Returns the source files that are covered by this test module\n",
      "        \"\"\"\n",
      "\n",
      "        # there must be a better way of doing this ...\n",
      "        return list(set([chunk.filepath for chunk in self.target_chunks]))\n",
      "  test_modules/models.py#230.46\n",
      "----------------------------------------------------------------------\n",
      "class TestModuleModel(Base):\n",
      "\n",
      "    def score(self, filename: str, src_repo: SourceRepo) -> int:\n",
      "        \"\"\"\n",
      "        Get score for a single file\n",
      "        \"\"\"\n",
      "        if filename not in self.get_covered_files():\n",
      "            raise Exception(\"Filename is not covered by TM\")\n",
      "\n",
      "        tgt_code_chunks = [\n",
      "            chunk for chunk in self.target_chunks if chunk.filepath == filename\n",
      "        ]\n",
      "        # coverage same for all tgt_code_chunks\n",
      "        cov = tgt_code_chunks[0].coverage\n",
      "        file = src_repo.find_file(tgt_code_chunks[0].filepath)\n",
      "        total_lines = len(file.lines)\n",
      "\n",
      "        total_covered = cov.covered\n",
      "        total_missing = cov.misses\n",
      "        chunk_covered = 0\n",
      "\n",
      "        for chunk in tgt_code_chunks:\n",
      "            chunk_covered += len(chunk.get_lines())\n",
      "\n",
      "        return chunk_covered + total_missing / total_lines if total_lines else 0\n",
      "\n",
      "    def agg_score(self, src_repo: SourceRepo) -> int:\n",
      "        \"\"\"\n",
      "        Get aggregate score over all covered source files\n",
      "        \"\"\"\n",
      "        agg_score = 0\n",
      "        all_files = self.get_covered_files()\n",
      "\n",
      "        for f in all_files:\n",
      "            agg_score += self.score(f, src_repo)\n",
      "\n",
      "        return agg_score / len(all_files) if len(all_files) > 0 else 0\n",
      "\n",
      "\n",
      "class BuildMappingRequest(TMSelectModeBase):\n",
      "    repo_name: str\n",
      "    overwrite: Optional[bool] = False\n",
      "\n",
      "\n",
      "class TestModuleReponse(BaseModel):\n",
      "    filepath: str\n",
      "    name: str\n",
      "    unit_tests: List[str]\n",
      "  test_modules/service.py#232.23\n",
      "----------------------------------------------------------------------\n",
      "def create_tm(*, db_session: Session, repo_id: str, tm: TestModule):\n",
      "    \"\"\"Create a test module and the nodes\"\"\"\n",
      "\n",
      "    tm_model = TestModuleModel(\n",
      "        name=tm.name,\n",
      "        testfilepath=str(tm.test_file.path),\n",
      "        commit_sha=tm.commit_sha,\n",
      "        repo_id=repo_id,\n",
      "    )\n",
      "\n",
      "    # need to commit before so node has access to tm_model.id\n",
      "    db_session.add(tm_model)\n",
      "    db_session.commit()\n",
      "\n",
      "    for node in tm.nodes:\n",
      "        create_node(\n",
      "            db_session=db_session,\n",
      "            node=node,\n",
      "            repo_id=repo_id,\n",
      "            filepath=tm_model.testfilepath,\n",
      "            test_module_id=tm_model.id,\n",
      "        )\n",
      "\n",
      "    return tm_model\n",
      "  test_modules/service.py#234.28\n",
      "----------------------------------------------------------------------\n",
      "def update_tm(*, db_session: Session, tm_model: TestModuleModel):\n",
      "    \"\"\"\n",
      "    Updates an existing TM\n",
      "    \"\"\"\n",
      "    db_session.merge(tm_model)\n",
      "    db_session.commit()\n",
      "\n",
      "    return tm_model\n",
      "\n",
      "\n",
      "def get_all_tms(*, db_session: Session, repo_id: str) -> List[TestModuleModel]:\n",
      "    \"\"\"\n",
      "    Query all TMs for a repo\n",
      "    \"\"\"\n",
      "    return (\n",
      "        db_session.query(TestModuleModel)\n",
      "        .filter(TestModuleModel.repo_id == repo_id)\n",
      "        .all()\n",
      "    )\n",
      "\n",
      "\n",
      "def get_tms_by_filename(\n",
      "    *, db_session: Session, repo_id: str, src_file: str\n",
      ") -> List[TestModuleModel]:\n",
      "    \"\"\"\n",
      "    Query all TMs for a repo\n",
      "    \"\"\"\n",
      "    all_tms = get_all_tms(db_session=db_session, repo_id=repo_id)\n",
      "    return [tm for tm in all_tms if src_file in tm.get_covered_files()]\n",
      "Cluster 4\n",
      "  cowboy_lib/coverage.py#27.25\n",
      "----------------------------------------------------------------------\n",
      "class TestCoverage:\n",
      "\n",
      "    def covered_lines(self) -> List[Tuple[str, List[int]]]:\n",
      "        cov_lines = [(cov.filename, cov.covered_lines) for cov in self.cov_list]\n",
      "        return cov_lines\n",
      "\n",
      "    def missing_lines(self) -> List[Tuple[str, List[int]]]:\n",
      "        cov_lines = [(cov.filename, cov.missing_lines) for cov in self.cov_list]\n",
      "        return cov_lines\n",
      "\n",
      "    def cov_list_str(self):\n",
      "        return \"\\n\".join([str(cov) for cov in self.cov_list])\n",
      "\n",
      "    def __repr__(self):\n",
      "        return f\"TestCoverage: {self.total_cov}, IsDiff:{self.isdiff}\"\n",
      "\n",
      "    def serialize(self):\n",
      "        return {\n",
      "            \"cov_list\": [cov.serialize() for cov in self.cov_list],\n",
      "            \"isdiff\": self.isdiff,\n",
      "        }\n",
      "\n",
      "    @classmethod\n",
      "    def deserialize(self, data: List[List]) -> \"TestCoverage\":\n",
      "        return TestCoverage(\n",
      "            [Coverage(**lines) for lines in data[\"cov_list\"]],\n",
      "            isdiff=data[\"isdiff\"],\n",
      "        )\n",
      "  llm/invoke_llm.py#31.37\n",
      "----------------------------------------------------------------------\n",
      "from typing import List, Tuple\n",
      "import asyncio\n",
      "\n",
      "from .models import BaseModel\n",
      "\n",
      "from .utils import (\n",
      "    # TurboModel,\n",
      "    extract_python_code,\n",
      "    extract_yaml_code,\n",
      "    extract_json_code,\n",
      ")\n",
      "\n",
      "\n",
      "async def invoke_llm_async(\n",
      "    prompt: str,\n",
      "    model: BaseModel,\n",
      "    n_times: int,\n",
      "    output: str = \"str\",\n",
      ") -> List[str]:\n",
      "    output = []\n",
      "\n",
      "    coroutines = []\n",
      "    for _ in range(n_times):\n",
      "        coroutines.append(model.query(prompt))\n",
      "\n",
      "    llm_outputs = await asyncio.gather(*coroutines)\n",
      "\n",
      "    # should add the other methods here\n",
      "    for out in llm_outputs:\n",
      "        if output == \"yaml\":\n",
      "            out = extract_yaml_code(out)\n",
      "        elif output == \"json\":\n",
      "            out = extract_json_code(out)\n",
      "        elif output == \"code\":\n",
      "            out = extract_python_code(out)\n",
      "\n",
      "    return llm_outputs\n",
      "  llm/models.py#38.27\n",
      "----------------------------------------------------------------------\n",
      "class OpenAIModel(BaseModel):\n",
      "\n",
      "    @retry(\n",
      "        wait=wait_random_exponential(min=1, max=15),\n",
      "        reraise=True,\n",
      "        stop=stop_after_attempt(3),\n",
      "        retry=retry_if_not_exception_type((CostLimitExceededError, RuntimeError)),\n",
      "    )\n",
      "    async def query(self, prompt: str) -> str:\n",
      "        \"\"\"\n",
      "        Query the OpenAI API with the given `history` and return the response.\n",
      "        \"\"\"\n",
      "\n",
      "        print(\"Querying MDOEL ....\")\n",
      "        try:\n",
      "            # Perform OpenAI API call\n",
      "            response = await self.client.chat.completions.create(\n",
      "                messages=[{\"role\": \"user\", \"content\": prompt}], model=self.api_model\n",
      "            )\n",
      "\n",
      "            input_tokens = response.usage.prompt_tokens\n",
      "            output_tokens = response.usage.completion_tokens\n",
      "            self.update_stats(input_tokens, output_tokens)\n",
      "            return response.choices[0].message.content\n",
      "\n",
      "        except BadRequestError as e:\n",
      "            raise CostLimitExceededError(\n",
      "                f\"Context window ({self.model_metadata['max_context']} tokens) exceeded\"\n",
      "            )\n",
      "  cowboy-server/main.py#83.47\n",
      "----------------------------------------------------------------------\n",
      "class ExceptionMiddleware(BaseHTTPMiddleware):\n",
      "    async def dispatch(\n",
      "        self, request: Request, call_next: RequestResponseEndpoint\n",
      "    ) -> StreamingResponse:\n",
      "        try:\n",
      "            response = await call_next(request)\n",
      "        except ValidationError as e:\n",
      "            log.exception(e)\n",
      "            response = JSONResponse(\n",
      "                status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n",
      "                content={\"detail\": e.errors(), \"error\": True},\n",
      "            )\n",
      "        except ValueError as e:\n",
      "            log.exception(e)\n",
      "            response = JSONResponse(\n",
      "                status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n",
      "                content={\n",
      "                    \"detail\": [\n",
      "                        {\"msg\": \"Unknown\", \"loc\": [\"Unknown\"], \"type\": \"Unknown\"}\n",
      "                    ],\n",
      "                    \"error\": True,\n",
      "                },\n",
      "            )\n",
      "        except CowboyRunTimeException as e:\n",
      "            log.exception(e)\n",
      "            response = JSONResponse(\n",
      "                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n",
      "                content={\n",
      "                    \"detail\": [{\"msg\": f\"Runtime error: {e.message}\"}],\n",
      "                    \"error\": True,\n",
      "                },\n",
      "            )\n",
      "        except Exception as e:\n",
      "            log.exception(e)\n",
      "            response = JSONResponse(\n",
      "                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n",
      "                content={\n",
      "                    \"detail\": [\n",
      "                        {\"msg\": \"Unknown\", \"loc\": [\"Unknown\"], \"type\": \"Unknown\"}\n",
      "                    ],\n",
      "                    \"error\": True,\n",
      "                },\n",
      "            )\n",
      "\n",
      "        return response\n",
      "\n",
      "\n",
      "token_registry = set()\n",
      "  src/exceptions.py#123.7\n",
      "----------------------------------------------------------------------\n",
      "from pydantic.errors import PydanticUserError\n",
      "\n",
      "\n",
      "class CowboyRunTimeException(Exception):\n",
      "    def __init__(self, message: str):\n",
      "        self.message = message\n",
      "        super().__init__(message)\n",
      "  experiments/augment_test.py#124.32\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.repo import SourceRepo, GitRepo\n",
      "from cowboy_lib.coverage import TestCoverage, Coverage\n",
      "from cowboy_lib.test_modules.test_module import TestModule\n",
      "from cowboy_lib.ast.code import NodeType\n",
      "from cowboy_lib.repo.source_file import NodeNotFound, SameNodeException\n",
      "\n",
      "from src.test_modules.models import TestModuleModel\n",
      "from src.repo.models import RepoConfig\n",
      "\n",
      "from pathlib import Path\n",
      "from git import Repo\n",
      "from logging import getLogger\n",
      "from typing import List, Tuple\n",
      "\n",
      "\n",
      "logger = getLogger(\"test_results\")\n",
      "\n",
      "\n",
      "class ExpVarDeleteFuncs(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "# TODO: implement on TestCoverage\n",
      "def find_file_cov_for_tm(tm: TestModule, base_cov: TestCoverage) -> Coverage:\n",
      "    try:\n",
      "        return next(\n",
      "            filter(\n",
      "                lambda x: x.filename == str(tm.targeted_files(base_path=False)[0]),\n",
      "                base_cov.cov_list,\n",
      "            )\n",
      "        )\n",
      "    except StopIteration:\n",
      "        return None\n",
      "  augment_test/composer.py#189.48\n",
      "----------------------------------------------------------------------\n",
      "class Composer:\n",
      "    \"\"\"\n",
      "    Used to instantiate different combinations of strategies for generating test cases\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        repo_name: str,\n",
      "        strat: AugmentStratType,\n",
      "        evaluator: EvaluatorType,\n",
      "        src_repo: SourceRepo,\n",
      "        test_input: TestCaseInput,\n",
      "        run_args: RunServiceArgs,\n",
      "        base_cov: TestCoverage,\n",
      "        api_key: str,\n",
      "        verify: bool = False,\n",
      "    ):\n",
      "        self.repo_name = repo_name\n",
      "        self.src_repo = src_repo\n",
      "        self.test_input = test_input\n",
      "        self.verify = verify\n",
      "        self.base_cov = base_cov\n",
      "        self.run_args = run_args\n",
      "\n",
      "        self.strat: BaseStrategy = AUGMENT_STRATS[strat](self.src_repo, self.test_input)\n",
      "        self.evaluator: Evaluator = AUGMENT_EVALS[evaluator](\n",
      "            self.repo_name, self.src_repo, self.run_args\n",
      "        )\n",
      "\n",
      "        model_name = \"gpt4\"\n",
      "        self.model = OpenAIModel(ModelArguments(model_name=model_name, api_key=api_key))\n",
      "\n",
      "    def get_strat_name(self) -> str:\n",
      "        return self.__class__.__name__\n",
      "\n",
      "    def filter_overlap_improvements(\n",
      "        self, tests: List[Tuple[Function, TestCoverage]]\n",
      "    ) -> List[Tuple[Function, TestCoverage]]:\n",
      "        no_overlap = []\n",
      "        overlap_cov = self.base_cov\n",
      "        for test, cov in tests:\n",
      "            new_cov = overlap_cov + cov\n",
      "            if new_cov.total_cov.covered > overlap_cov.total_cov.covered:\n",
      "                no_overlap.append((test, cov))\n",
      "                overlap_cov = new_cov\n",
      "\n",
      "        return no_overlap\n",
      "\n",
      "    # TODO: this function name is a lie, we should parallelize this\n",
      "  augment_test/composer.py#190.33\n",
      "----------------------------------------------------------------------\n",
      "class Composer:\n",
      "    async def gen_test_parallel(self, n_times: int) -> Tuple[\n",
      "        List[Tuple[Function, TestCoverage]],\n",
      "        List[Tuple[Function, TestError]],\n",
      "        List[Function],\n",
      "    ]:\n",
      "\n",
      "        improved_tests = []\n",
      "        failed_tests = []\n",
      "        no_improve_tests = []\n",
      "\n",
      "        # TODO: here is whee we initialize the StartCodeTx\n",
      "        prompt = self.strat.build_prompt()\n",
      "        print(f\"Prompt: {prompt}\")\n",
      "\n",
      "        model_res = await invoke_llm_async(prompt, self.model, n_times)\n",
      "\n",
      "        llm_results = [self.strat.parse_llm_res(res) for res in model_res]\n",
      "        test_results = [StratResult(res, self.test_input.path) for res in llm_results]\n",
      "\n",
      "        improved, failed, no_improve = await self.evaluator(\n",
      "            test_results,\n",
      "            self.test_input,\n",
      "            self.base_cov,\n",
      "            n_times=n_times,\n",
      "        )\n",
      "\n",
      "        improved_tests.extend(improved)\n",
      "        filtered_improved = self.filter_overlap_improvements(improved_tests)\n",
      "        improved_tests = filtered_improved\n",
      "\n",
      "        failed_tests.extend(failed)\n",
      "        no_improve_tests.extend(no_improve)\n",
      "\n",
      "        return improved_tests, failed_tests, no_improve_tests\n",
      "  augment_test/composer.py#191.75\n",
      "----------------------------------------------------------------------\n",
      "class Composer:\n",
      "\n",
      "    async def gen_test_serial_additive(self, n_times: int) -> Tuple[\n",
      "        List[Tuple[Function, TestCoverage]],\n",
      "        List[Tuple[Function, TestError]],\n",
      "        List[Function],\n",
      "    ]:\n",
      "        if not isinstance(self.evaluator, AugmentAdditiveEvaluator):\n",
      "            raise Exception(\n",
      "                f\"Expected AugmentAdditiveEvaluator, got {self.evaluator.__class__}\"\n",
      "            )\n",
      "\n",
      "        improved_tests = []\n",
      "        failed_tests = []\n",
      "        no_improve_tests = []\n",
      "        prompt = self.strat.build_prompt()\n",
      "\n",
      "        print(\"Prompt: \", prompt)\n",
      "\n",
      "        for _ in range(n_times):\n",
      "            retries = LLM_RETRIES\n",
      "            src_file = None\n",
      "            while retries > 0 and not src_file:\n",
      "                try:\n",
      "                    llm_res = await invoke_llm_async(\n",
      "                        prompt,\n",
      "                        model=self.model,\n",
      "                        n_times=1,\n",
      "                    )\n",
      "                    src_file = self.strat.parse_llm_res(llm_res[0])\n",
      "                except (SyntaxError, ValueError, LintException):\n",
      "                    testgen_logger.info(f\"LLM syntax error ... {retries} left\")\n",
      "                    retries -= 1\n",
      "                    continue\n",
      "\n",
      "            if not src_file:\n",
      "                raise CowboyRunTimeException(\n",
      "                    f\"LLM generation failed for {self.test_input}\"\n",
      "                )\n",
      "\n",
      "            test_result = [StratResult(src_file, self.test_input.path)]\n",
      "            improved, failed, no_improve = await self.evaluator(\n",
      "                test_result,\n",
      "                self.test_input,\n",
      "                self.base_cov,\n",
      "                n_times=n_times,\n",
      "            )\n",
      "            improved_tests.extend(improved)\n",
      "            filtered_improved = self.filter_overlap_improvements(improved_tests)\n",
      "            improved_tests = filtered_improved\n",
      "\n",
      "            # update test input with new functions that improved coverage\n",
      "            for new_func in [\n",
      "                func\n",
      "                for func, _ in improved\n",
      "                if func in [f[0] for f in filtered_improved]\n",
      "            ]:\n",
      "                self.test_input.test_file.append(\n",
      "                    new_func.to_code(),\n",
      "                    # wrong too, we need to check the\n",
      "                    class_name=new_func.scope.name if new_func.scope else \"\",\n",
      "                )\n",
      "\n",
      "            failed_tests.extend(failed)\n",
      "            no_improve_tests.extend(no_improve)\n",
      "\n",
      "        return improved_tests, failed_tests, no_improve_tests\n",
      "\n",
      "    async def generate_test(self, n_times: int) -> Tuple[\n",
      "        List[Tuple[Function, TestCoverage]],\n",
      "        List[Tuple[Function, TestError]],\n",
      "        List[Function],\n",
      "    ]:\n",
      "        if isinstance(self.evaluator, AugmentAdditiveEvaluator):\n",
      "            return await self.gen_test_serial_additive(n_times)\n",
      "        elif isinstance(self.evaluator, AugmentParallelEvaluator):\n",
      "            return await self.gen_test_parallel(n_times)\n",
      "  strats/__init__.py#201.18\n",
      "----------------------------------------------------------------------\n",
      "from .augment_strat import AugmentClassStrat\n",
      "from .augment_with_ctxt_file import AugmentClassWithCtxtStrat\n",
      "from .augment_base import AugmentTestStrategy\n",
      "from .augment_with_missing import AugmentModuleMissing\n",
      "\n",
      "from enum import Enum\n",
      "\n",
      "AUGMENT_STRATS = {\n",
      "    \"VANILLA\": AugmentClassStrat,\n",
      "    \"WITH_CTXT\": AugmentClassWithCtxtStrat,\n",
      "    \"MODULE_MISSING\": AugmentModuleMissing,\n",
      "}\n",
      "\n",
      "\n",
      "class AugmentStratType(Enum):\n",
      "    VANILLA = \"VANILLA\"\n",
      "    WITH_CTXT = \"WITH_CTXT\"\n",
      "    MODULE_MISSING = \"MODULE_MISSING\"\n",
      "Cluster 5\n",
      "  repo/source_file.py#65.28\n",
      "----------------------------------------------------------------------\n",
      "class TestFile(SourceFile):\n",
      "    def __init__(self, *args, **kwargs):\n",
      "        super().__init__(*args, **kwargs)\n",
      "\n",
      "    @property\n",
      "    def test_nodes(self) -> List[ASTNode]:\n",
      "        return [n for n in self.functions + self.classes if n.is_test]\n",
      "\n",
      "    def test_funcs(self) -> List[Function]:\n",
      "        return [func for func in self.functions if func.is_test]\n",
      "\n",
      "    def test_classes(self) -> List[Class]:\n",
      "        return [c for c in self.classes if c.is_test]\n",
      "\n",
      "    def __repr__(self):\n",
      "        return f\"{self.path}\"\n",
      "\n",
      "    def new_test_funcs(self, new_file: \"TestFile\") -> List[Function]:\n",
      "        \"\"\"\n",
      "        Returns a list of nodes that are in the new file but not in the current file\n",
      "        \"\"\"\n",
      "        assert Path(self._path) == Path(new_file.path)\n",
      "\n",
      "        return [\n",
      "            f\n",
      "            for f in new_file.test_funcs()\n",
      "            if f.name not in [my_f.name for my_f in self.test_funcs()]\n",
      "        ]\n",
      "  repo/source_repo.py#66.33\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.repo.source_file import TestFile, SourceFile, Function, Class\n",
      "\n",
      "from pathlib import Path\n",
      "from functools import reduce\n",
      "from typing import List, Optional, Iterator, Tuple, TYPE_CHECKING\n",
      "\n",
      "from logging import getLogger\n",
      "\n",
      "logger = getLogger(\"test_results\")\n",
      "longterm_logger = getLogger(\"longterm\")\n",
      "\n",
      "\n",
      "# TODO: should we combine git/src_repo into one?\n",
      "class SourceRepo:\n",
      "    \"\"\"\n",
      "    Used by the TestStrategy to access files and their contents\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(self, repo_path: Path, files_list: List[str] = []):\n",
      "        self.repo_path = repo_path\n",
      "        self.files_list = files_list\n",
      "        self.source_files: List[SourceFile] = self._init_source_files(files_list)\n",
      "        # counter = Counter([f.path for f in self.source_files]).most_common()\n",
      "        # print(counter)\n",
      "\n",
      "    def get_rel_path(self, file_path: Path) -> str:\n",
      "        \"\"\"\n",
      "        Get the path relative to the source repo\n",
      "        \"\"\"\n",
      "        return file_path.relative_to(self.repo_path)\n",
      "\n",
      "    @property\n",
      "    def test_files(self) -> List[TestFile]:\n",
      "        return [f for f in self.source_files if isinstance(f, TestFile)]\n",
      "  repo/source_repo.py#67.23\n",
      "----------------------------------------------------------------------\n",
      "class SourceRepo:\n",
      "\n",
      "    def _init_source_files(self, files_list=[]) -> List[TestFile]:\n",
      "        \"\"\"\n",
      "        Finds all test files in the repo\n",
      "        \"\"\"\n",
      "        source_files = []\n",
      "        for path in self.repo_path.rglob(\"*\"):\n",
      "            if path.is_file() and path.name.endswith(\".py\"):\n",
      "                if files_list:\n",
      "                    if path not in [self.repo_path / f for f in files_list]:\n",
      "                        continue\n",
      "                with open(path, \"r\", encoding=\"utf-8\") as f:\n",
      "                    lines = f.read().split(\"\\n\")\n",
      "                try:\n",
      "                    rel_path = self.get_rel_path(path)\n",
      "                    source_file = (\n",
      "                        TestFile(lines, rel_path)\n",
      "                        if path.name.startswith(\"test_\")\n",
      "                        else SourceFile(lines, rel_path)\n",
      "                    )\n",
      "                    source_files.append(source_file)\n",
      "                except SyntaxError as e:\n",
      "                    logger.error(f\"AST Syntax error while parsing: {path}\")\n",
      "\n",
      "        return source_files\n",
      "  test_modules/test_module.py#72.90\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.coverage import Coverage, get_full_path\n",
      "from cowboy_lib.repo.source_file import TestFile, ASTNode, NodeNotFound, NodeType\n",
      "from cowboy_lib.utils import get_current_git_commit\n",
      "\n",
      "from typing import List, Optional, TYPE_CHECKING, Tuple\n",
      "from pathlib import Path\n",
      "\n",
      "from cowboy_lib.repo.source_repo import SourceRepo\n",
      "from cowboy_lib.test_modules.target_code import TargetCode\n",
      "\n",
      "\n",
      "class IncompatibleCommit(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class TestModule:\n",
      "    \"\"\"\n",
      "    A TestFile with a list of selected Tests\n",
      "    \"\"\"\n",
      "\n",
      "    def __init__(\n",
      "        self,\n",
      "        test_file: TestFile,\n",
      "        nodes: List[ASTNode],\n",
      "        commit_sha: str,\n",
      "        # hack: to check if we are not desync'd from the repo\n",
      "        check_commit: bool = False,\n",
      "        chunks: List[TargetCode] = [],\n",
      "    ):\n",
      "        # wtf ...\n",
      "        test_folder = Path(*test_file.path.parts[:2])\n",
      "        if check_commit:\n",
      "            assert commit_sha == get_current_git_commit(test_folder)\n",
      "\n",
      "        self.commit_sha = commit_sha\n",
      "        self.test_file = test_file\n",
      "        self.chunks: List[TargetCode] = chunks\n",
      "        self.cov_diff = None\n",
      "\n",
      "        # class or test file\n",
      "        self.nodes = nodes\n",
      "        self._isclass = True if self.nodes[0].type is NodeType.Class else False\n",
      "        self.name = (\n",
      "            self.test_file.path.name if not self._isclass else self.nodes[0].name\n",
      "        )\n",
      "\n",
      "    def __eq__(self, other: \"TestModule\"):\n",
      "        return self.test_file.path + self.name == other.test_file.path + other.name\n",
      "\n",
      "    @property\n",
      "    def tests(self) -> List[ASTNode]:\n",
      "        return (\n",
      "            self.nodes\n",
      "            if not self._isclass\n",
      "            else [\n",
      "                func\n",
      "                for func in self.test_file.test_funcs()\n",
      "                if func.scope.name == self.name\n",
      "            ]\n",
      "        )\n",
      "\n",
      "    def targeted_files(self):\n",
      "        \"\"\"\n",
      "        The list of files that the test module is testing\n",
      "        \"\"\"\n",
      "        # kinda of a hack, but we always assume that base path is in the form\n",
      "        # repos/<repo_name> appended to the filepath\n",
      "        # fp = lambda p: base_path if base_path else Path(*p.parts[2:])\n",
      "\n",
      "        return list(set([c.filepath for c in self.chunks]))\n",
      "\n",
      "    @property\n",
      "    def path(self):\n",
      "        return self.test_file.path\n",
      "\n",
      "    def target_test_file(self) -> Path:\n",
      "        \"\"\"\n",
      "        Returns the test file that will be modified by test strategy\n",
      "        to generate new tests\n",
      "        \"\"\"\n",
      "        return self.test_file.path\n",
      "\n",
      "    def num_lines(self, filename: Optional[str] = \"\"):\n",
      "        if not filename:\n",
      "            chunks = self.chunks\n",
      "        else:\n",
      "            chunks = [c for c in self.chunks if c.filepath == filename]\n",
      "\n",
      "        return sum(\n",
      "            [c.range[1] - c.range[0] if c.range[1] - c.range[0] else 1 for c in chunks]\n",
      "        )\n",
      "  test_modules/test_module.py#74.22\n",
      "----------------------------------------------------------------------\n",
      "class TestModule:\n",
      "\n",
      "    def did_change(self, new_file: TestFile):\n",
      "        \"\"\"\n",
      "        Compares the test file ranges\n",
      "        \"\"\"\n",
      "        for n in new_file.test_nodes:\n",
      "            for test_node in self.tests:\n",
      "                if (\n",
      "                    n.name == test_node.name\n",
      "                    and n.range != test_node.range\n",
      "                    # NOTE: this takes into account line additions and deletions\n",
      "                    # but not modifications, we leaving that for later when the diff\n",
      "                    # parsing interface gets built\n",
      "                    and n.range[1] - n.range[0]\n",
      "                    != test_node.range[1] - test_node.range[0]\n",
      "                ):\n",
      "                    new_mods = n.range[1] - n.range[0]\n",
      "                    old_test = test_node.range[1] - test_node.range[0]\n",
      "                    if new_mods > old_test:\n",
      "                        print(\"Tests were added!\")\n",
      "                    else:\n",
      "                        print(\"Tests were deleted!\")\n",
      "                    return True\n",
      "        return False\n",
      "  cowboy_lib/utils.py#79.28\n",
      "----------------------------------------------------------------------\n",
      "from pathlib import Path\n",
      "import subprocess\n",
      "import os\n",
      "import uuid\n",
      "import random\n",
      "import string\n",
      "import shutil\n",
      "\n",
      "\n",
      "def get_current_git_commit(repo_path: Path) -> str:\n",
      "    \"\"\"\n",
      "    Uses subprocess to get the current git commit hash.\n",
      "\n",
      "    Returns:\n",
      "        str: The current git commit hash.\n",
      "    \"\"\"\n",
      "    try:\n",
      "        commit_hash = (\n",
      "            subprocess.check_output(\n",
      "                [\"cd\", str(repo_path.resolve()), \"&&\", \"git\", \"rev-parse\", \"HEAD\"],\n",
      "                shell=True,\n",
      "            )\n",
      "            .strip()\n",
      "            .decode(\"utf-8\")\n",
      "        )\n",
      "        return commit_hash\n",
      "    except subprocess.CalledProcessError as e:\n",
      "        print(f\"Error getting current git commit: {e}\")\n",
      "        return \"\"\n",
      "  test_modules/iter_tms.py#228.41\n",
      "----------------------------------------------------------------------\n",
      "from cowboy_lib.utils import get_current_git_commit\n",
      "from cowboy_lib.repo.source_repo import SourceRepo\n",
      "\n",
      "from src.test_modules.models import TestModule\n",
      "\n",
      "from typing import List\n",
      "\n",
      "\n",
      "def iter_test_modules(src_repo: SourceRepo) -> List[TestModule]:\n",
      "    \"\"\"\n",
      "    Generator for TestModules\n",
      "    TestModules can be either be:\n",
      "    1. All the individual functions inside a TestFile\n",
      "    2. All the functions inside a class inside a TestFile\n",
      "    3. Some of the individual functions inside a TestFile\n",
      "    4. Some of the functions inside a class inside a TestFile\n",
      "    \"\"\"\n",
      "    test_modules: List[TestModule] = []\n",
      "    for test_file in src_repo.test_files:\n",
      "        ind_funcs = [f for f in test_file.test_funcs() if not f.scope]\n",
      "        if ind_funcs:\n",
      "            func_module = TestModule(\n",
      "                test_file, ind_funcs, get_current_git_commit(src_repo.repo_path)\n",
      "            )\n",
      "            test_modules.append(func_module)\n",
      "\n",
      "        for test_class in test_file.test_classes():\n",
      "            class_module = TestModule(\n",
      "                test_file, [test_class], get_current_git_commit(src_repo.repo_path)\n",
      "            )\n",
      "            test_modules.append(class_module)\n",
      "\n",
      "    # NOTE: literally dont work and literally dont need\n",
      "    # name_counter = Counter([tm.name for tm in test_modules])\n",
      "    # while any([count > 1 for count in name_counter.values()]):\n",
      "    #     for tm in test_modules:\n",
      "    #         if name_counter[tm.name] > 1:\n",
      "    #             tm.name = get_new_name(tm.name, tm.test_file.path)\n",
      "    #             name_counter = Counter([tm.name for tm in test_modules])\n",
      "\n",
      "    return test_modules\n",
      "Cluster 6\n",
      "  auth/views.py#106.16\n",
      "----------------------------------------------------------------------\n",
      "@auth_router.post(\"/user/update/openai-key\")\n",
      "def update_oai_key(\n",
      "    request: UpdateOAIKey,\n",
      "    curr_user: CowboyUser = Depends(get_current_user),\n",
      "    db_session: Session = Depends(get_db),\n",
      "):\n",
      "    user = get(db_session=db_session, user_id=curr_user.id)\n",
      "    if not user:\n",
      "        raise HTTPException(\n",
      "            status_code=status.HTTP_404_NOT_FOUND,\n",
      "            detail=\"User not found\",\n",
      "        )\n",
      "\n",
      "    store_oai_key(user_id=user.id, api_key=request.openai_api_key)\n",
      "\n",
      "    return HTTPSuccess()\n",
      "  health/views.py#133.12\n",
      "----------------------------------------------------------------------\n",
      "from fastapi import APIRouter, Depends\n",
      "from src.models import HTTPSuccess\n",
      "from src.auth.service import get_current_user\n",
      "from src.auth.models import CowboyUser\n",
      "\n",
      "\n",
      "health_router = APIRouter()\n",
      "\n",
      "\n",
      "@health_router.get(\"/health\")\n",
      "async def health():\n",
      "    return HTTPSuccess()\n",
      "  src/models.py#135.46\n",
      "----------------------------------------------------------------------\n",
      "from datetime import datetime\n",
      "from sqlalchemy import Column, DateTime, event\n",
      "from pydantic import BaseModel, Field\n",
      "from pydantic.types import SecretStr\n",
      "\n",
      "from typing import Annotated\n",
      "\n",
      "PrimaryKey = Annotated[int, Field(gt=0, lt=2147483647)]\n",
      "NameStr = Annotated[\n",
      "    str, Field(pattern=r\"^(?!\\s*$).+\", strip_whitespace=True, min_length=3)\n",
      "]\n",
      "\n",
      "\n",
      "class TimeStampMixin(object):\n",
      "    \"\"\"Timestamping mixin\"\"\"\n",
      "\n",
      "    created_at = Column(DateTime, default=datetime.utcnow)\n",
      "    created_at._creation_order = 9998\n",
      "    updated_at = Column(DateTime, default=datetime.utcnow)\n",
      "    updated_at._creation_order = 9998\n",
      "\n",
      "    @staticmethod\n",
      "    def _updated_at(mapper, connection, target):\n",
      "        target.updated_at = datetime.utcnow()\n",
      "\n",
      "    @classmethod\n",
      "    def __declare_last__(cls):\n",
      "        event.listen(cls, \"before_update\", cls._updated_at)\n",
      "\n",
      "\n",
      "class CowboyBase(BaseModel):\n",
      "    class Config:\n",
      "        from_attributes = True\n",
      "        validate_assignment = True\n",
      "        arbitrary_types_allowed = True\n",
      "        str_strip_whitespace = True\n",
      "\n",
      "        json_encoders = {\n",
      "            # custom output conversion for datetime\n",
      "            datetime: lambda v: v.strftime(\"%Y-%m-%dT%H:%M:%SZ\") if v else None,\n",
      "            SecretStr: lambda v: v.get_secret_value() if v else None,\n",
      "        }\n",
      "\n",
      "\n",
      "class HTTPSuccess(BaseModel):\n",
      "    msg: str = \"Success\"\n",
      "  repo/models.py#144.53\n",
      "----------------------------------------------------------------------\n",
      "class LangConf(CowboyBase):\n",
      "    \"\"\"\n",
      "    Holds the language/framework specific settings\n",
      "    for a repo\n",
      "    \"\"\"\n",
      "\n",
      "    # currently I expect only an interpreter/compiler path that points\n",
      "    # to the runtime for the targeted repo\n",
      "    interp: str\n",
      "\n",
      "\n",
      "class PythonConf(LangConf):\n",
      "    language: str = \"python\"\n",
      "    cov_folders: List[str]\n",
      "    test_folder: str\n",
      "    interp: str\n",
      "    pythonpath: str\n",
      "\n",
      "    def get(self, __name: str, default: Any = None) -> Any:\n",
      "        return self.dict().get(__name, default)\n",
      "\n",
      "\n",
      "class RepoConfigBase(CowboyBase):\n",
      "    repo_name: str\n",
      "    url: str\n",
      "    source_folder: str\n",
      "    cloned_folders: List[str]\n",
      "    python_conf: PythonConf\n",
      "\n",
      "    language: Optional[Language] = Field(default=\"python\")\n",
      "    is_experiment: Optional[bool] = Field(default=False)\n",
      "    main: Optional[str] = Field(default=\"main\")\n",
      "    remote: Optional[str] = Field(default=\"origin\")\n",
      "\n",
      "\n",
      "class RepoConfigGet(RepoConfigBase):\n",
      "    pass\n",
      "\n",
      "\n",
      "class RepoConfigCreate(RepoConfigBase):\n",
      "    repo_name: str\n",
      "\n",
      "\n",
      "class RepoConfigList(CowboyBase):\n",
      "    repo_list: List[RepoConfigBase]\n",
      "\n",
      "\n",
      "class RepoConfigRemoteCommit(CowboyBase):\n",
      "    sha: str\n",
      "\n",
      "\n",
      "# class RepoConfigDelete(BaseModel):\n",
      "#     repo_name: str\n",
      "  test_gen/models.py#216.23\n",
      "----------------------------------------------------------------------\n",
      "class TMSelectModeBase(BaseModel):\n",
      "    mode: TMSelectMode\n",
      "    files: Optional[List[str]]\n",
      "    tms: Optional[List[str]]\n",
      "\n",
      "    @validator(\"files\", always=True)\n",
      "    def check_files(cls, v, values):\n",
      "        if values.get(\"mode\") == TMSelectMode.FILE and not v:\n",
      "            raise ValueError(\"files must be specified if mode is FILE\")\n",
      "        return v\n",
      "\n",
      "    @validator(\"tms\", always=True)\n",
      "    def check_tms(cls, v, values):\n",
      "        if values.get(\"mode\") == TMSelectMode.TM and not v:\n",
      "            raise ValueError(\"tms must be specfied if mode is TM\")\n",
      "        return v\n",
      "\n",
      "\n",
      "class AugmentTestRequest(TMSelectModeBase):\n",
      "    repo_name: str\n",
      "\n",
      "\n",
      "class AugmentTestResponse(CowboyBase):\n",
      "    session_id: str\n",
      "Cluster 7\n",
      "  ast/code.py#8.32\n",
      "----------------------------------------------------------------------\n",
      "class Function(ASTNode):\n",
      "    def __init__(self, *args, **kwargs):\n",
      "        # should replace this with ... a prototype that contains .name property\n",
      "        # self.scope: Class = kwargs.pop(\"scope\", [])\n",
      "        self.arguments = kwargs.pop(\"arguments\", [])\n",
      "\n",
      "        super().__init__(*args, **kwargs)\n",
      "\n",
      "        self.is_test = True if self._name.startswith(\"test\") else False\n",
      "\n",
      "    def is_meth(self):\n",
      "        return bool(self.scope)\n",
      "\n",
      "    def __str__(self):\n",
      "        return f\"{self._name}({', '.join([arg.__str__() for arg in self.arguments])})\"\n",
      "\n",
      "    def is_method(self):\n",
      "        return self.scope is not None\n",
      "\n",
      "    def func_name(self):\n",
      "        return self._name.split(\".\")[-1]\n",
      "\n",
      "    @property\n",
      "    def name(self):\n",
      "        scope_prefix = f\"{self.scope.name}.\" if self.scope else \"\"\n",
      "        return f\"{scope_prefix}{self._name}\"\n",
      "\n",
      "\n",
      "class NodeType(Enum):\n",
      "    Function = Function.__name__\n",
      "    Class = Class.__name__\n",
      "    Decorator = Decorator.__name__\n",
      "  repo/source_file.py#59.91\n",
      "----------------------------------------------------------------------\n",
      "from typing import List, Optional, Tuple\n",
      "from pathlib import Path\n",
      "from difflib import unified_diff\n",
      "\n",
      "from cowboy_lib.ast import Class, Function, ASTNode, NodeType\n",
      "from cowboy_lib.ast import PythonAST\n",
      "from cowboy_lib.utils import locate_python_interpreter\n",
      "\n",
      "from logging import getLogger\n",
      "from copy import deepcopy\n",
      "\n",
      "import subprocess\n",
      "\n",
      "\n",
      "logger = getLogger(\"test_results\")\n",
      "longterm_logger = getLogger(\"longterm\")\n",
      "\n",
      "\n",
      "class LintException(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class SameNodeException(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class NodeNotFound(Exception):\n",
      "    pass\n",
      "\n",
      "\n",
      "class SourceFile:\n",
      "    def __init__(\n",
      "        self,\n",
      "        lines: List[str],\n",
      "        path: Path,\n",
      "        language: str = \"python\",\n",
      "    ):\n",
      "        self._path = path\n",
      "        self._lang = language\n",
      "\n",
      "        self.functions: List[Function] = []\n",
      "        self.classes: List[Class] = []\n",
      "        self.lines: List[str] = []\n",
      "        # self.imports: List[str] = []\n",
      "\n",
      "        self.update_file_state(lines)\n",
      "\n",
      "    def clone(self) -> \"SourceFile\":\n",
      "        return deepcopy(self)\n",
      "\n",
      "    @property\n",
      "    def path(self):\n",
      "        return self._path\n",
      "\n",
      "    def update_file_state(self, lines: List[str]):\n",
      "        \"\"\"\n",
      "        Updates instance variables\n",
      "        \"\"\"\n",
      "        assert isinstance(lines, list)\n",
      "\n",
      "        # REFACTOR-AST: start here first, this is where we convert\n",
      "        # AST into our code-object representation of the src code\n",
      "        self.ast_parser = PythonAST(\"\\n\".join(lines))\n",
      "        self.functions, self.classes = self.ast_parser.parse()\n",
      "        self.lines = lines\n",
      "\n",
      "    def __repr__(self):\n",
      "        return f\"{self.path}\"\n",
      "\n",
      "    def diff(self, other: \"SourceFile\"):\n",
      "        if not isinstance(other, SourceFile):\n",
      "            raise TypeError(\"Can only diff SourceFile instances\")\n",
      "\n",
      "        a = self.to_code().splitlines(keepends=True)\n",
      "        b = other.to_code().splitlines(keepends=True)\n",
      "        diff = \"\".join(unified_diff(a, b))\n",
      "\n",
      "        return diff\n",
      "\n",
      "    # this would be another easy test for modification in test_parsing\n",
      "    # commit: c58ded2\n",
      "    def find_class(self, class_name: str) -> Optional[Class]:\n",
      "        \"\"\"\n",
      "        Finds a class by name\n",
      "        \"\"\"\n",
      "        return self.find_by_nodetype(class_name, node_type=NodeType.Class)\n",
      "\n",
      "    def find_function(self, function_name: str) -> Optional[Function]:\n",
      "        \"\"\"\n",
      "        Finds a function by name\n",
      "        \"\"\"\n",
      "        return self.find_by_nodetype(function_name, node_type=NodeType.Function)\n",
      "  experiments/augment_test.py#126.43\n",
      "----------------------------------------------------------------------\n",
      "def create_nuked_branch(\n",
      "    tms: List[TestModule],\n",
      "    src_repo: SourceRepo,\n",
      "    git_repo: GitRepo,\n",
      "    branch_name: str,\n",
      "    to_keep: int = 0,\n",
      "    to_delete: int = 0,\n",
      "):\n",
      "    \"\"\"\n",
      "    Modifies all test files by adding or deleting a set number of tests, then commits\n",
      "    the changes to\n",
      "    \"\"\"\n",
      "    total_deleted = 0\n",
      "    for tm in tms:\n",
      "        # TODO: would need to change this loop to handle files\n",
      "        logger.info(f\"Generating augmented tests for {tm.name} in {tm.path}\")\n",
      "\n",
      "        to_exclude = []\n",
      "        # BUG: tm.tests gets modified somehow\n",
      "        num_to_del = num_funcs_to_delete(tm, to_keep=to_keep, to_delete=to_delete)\n",
      "        total_tests = len(tm.tests)\n",
      "\n",
      "        logger.info(f\"Deleting {num_to_del}/{total_tests} tests from {tm.name}\")\n",
      "\n",
      "        for func in tm.tests[:num_to_del]:\n",
      "            try:\n",
      "                to_exclude.append((func, tm.test_file.path))\n",
      "                # CARE: this operation has changes state of src_repo,\n",
      "                # which is then propagated to strategy below\n",
      "                src_repo.find_file(tm.path).delete(\n",
      "                    func.name, node_type=NodeType.Function\n",
      "                )\n",
      "                # mirror the modifications made to src_repo\n",
      "                # CARE: this only modifies TestFile, but not the nodes\n",
      "                # TODO: figure out why the double delete here didnt work\n",
      "                # tm.test_file.delete(func.name, node_type=NodeType.Function)\n",
      "                src_repo.write_file(tm.path)\n",
      "                total_deleted += 1\n",
      "            except (NodeNotFound, SameNodeException) as e:\n",
      "                print(e)\n",
      "                continue\n",
      "\n",
      "    git_repo.checkout(branch_name, new=True)\n",
      "    git_repo.add_n_commit([str(tm.path) for tm in tms], f\"Delete {total_deleted} tests\")\n",
      "Cluster 8\n",
      "  repo/source_file.py#62.13\n",
      "----------------------------------------------------------------------\n",
      "class SourceFile:\n",
      "\n",
      "    def delete(self, node_name: str, node_type: NodeType = NodeType.Function) -> None:\n",
      "        \"\"\"\n",
      "        Deletes a new function or class to the file, and updates SourceFile instance accordingly without hitting file\n",
      "        \"\"\"\n",
      "\n",
      "        node = self.find_by_nodetype(node_name, node_type=node_type)\n",
      "        start, end = node.range\n",
      "\n",
      "        longterm_logger.info(f\"Deleting: {node.name} => {start} to {end}\")\n",
      "\n",
      "        lines = self.lines[:start] + self.lines[end + 1 :]\n",
      "        self.update_file_state(self.to_linted_code(lines).split(\"\\n\"))\n",
      "\n",
      "    # TODO: specify other code linter here\n",
      "  repo/source_file.py#63.29\n",
      "----------------------------------------------------------------------\n",
      "class SourceFile:\n",
      "    def to_linted_code(self, lines) -> str:\n",
      "        \"\"\"\n",
      "        Lint generated code file\n",
      "        \"\"\"\n",
      "        self.i = 0 if getattr(self, \"i\", None) is None else self.i + 1\n",
      "        interp = locate_python_interpreter()\n",
      "\n",
      "        black_cmd_str = f\"{interp} -m black \"\n",
      "        tmp_file = f\"/tmp/test{str(self.i)}.py\"\n",
      "        with open(tmp_file, mode=\"w+t\", encoding=\"utf-8\") as temp_file:\n",
      "            # temp_file_name = temp_file.name\n",
      "            temp_file.write(\"\\n\".join(lines))\n",
      "            temp_file.flush()\n",
      "\n",
      "            process = subprocess.Popen(\n",
      "                black_cmd_str + tmp_file,\n",
      "                shell=True,\n",
      "                stdout=subprocess.PIPE,\n",
      "                stderr=subprocess.PIPE,\n",
      "            )\n",
      "            stdout, stderr = process.communicate()\n",
      "            if stderr:\n",
      "                stderr = stderr.decode(\"utf-8\")\n",
      "                if \"error:\" in stderr:\n",
      "                    raise LintException(f\"Error while linting: {stderr}\")\n",
      "\n",
      "            with open(tmp_file, \"r\") as temp_file:\n",
      "                linted_code = temp_file.read()\n",
      "\n",
      "        return linted_code\n",
      "  cowboy_lib/utils.py#80.36\n",
      "----------------------------------------------------------------------\n",
      "def locate_python_interpreter():\n",
      "    possible_interpreters = [\"python\", \"python3\"]\n",
      "\n",
      "    for interpreter in possible_interpreters:\n",
      "        # Check if the interpreter is in PATH\n",
      "        path = shutil.which(interpreter)\n",
      "        if path:\n",
      "            return path\n",
      "\n",
      "    # Try manually common locations\n",
      "    common_locations = [\n",
      "        \"/usr/bin/python\",\n",
      "        \"/usr/local/bin/python\",\n",
      "        \"/usr/bin/python3\",\n",
      "        \"/usr/local/bin/python3\",\n",
      "        \"/bin/python\",\n",
      "        \"/bin/python3\",\n",
      "        \"/usr/sbin/python\",\n",
      "        \"/usr/sbin/python3\",\n",
      "    ]\n",
      "\n",
      "    for location in common_locations:\n",
      "        if os.path.isfile(location) and os.access(location, os.X_OK):\n",
      "            return location\n",
      "\n",
      "    # As a last resort, try running \"python --version\" and \"python3 --version\"\n",
      "    for interpreter in possible_interpreters:\n",
      "        try:\n",
      "            result = subprocess.run(\n",
      "                [interpreter, \"--version\"], capture_output=True, text=True\n",
      "            )\n",
      "            if result.returncode == 0:\n",
      "                return interpreter\n",
      "        except (subprocess.CalledProcessError, FileNotFoundError):\n",
      "            continue\n",
      "\n",
      "    raise FileNotFoundError(\"Python interpreter not found on this host\")\n",
      "Cluster 9\n",
      "  repo/diff.py#47.28\n",
      "----------------------------------------------------------------------\n",
      "class CommitDiff:\n",
      "\n",
      "    def _segment_diffs(self, patch: str) -> List[Diff]:\n",
      "        \"\"\"\n",
      "        Segments the patch into diffs, where each diff marks whether a file has been\n",
      "        modified, created anew, or deleted\n",
      "        \"\"\"\n",
      "\n",
      "        diff_sections = []\n",
      "        diff_starts = find_substring(patch, \"diff --git\")\n",
      "        if not diff_starts:\n",
      "            diff_starts = find_substring(patch, \"---\")\n",
      "\n",
      "        try:\n",
      "            start = diff_starts.pop(0)\n",
      "        except IndexError:\n",
      "            raise DiffsNotFoundException(\"No diff sections found in patch\")\n",
      "\n",
      "        for end in diff_starts:\n",
      "            diff_sections.append(patch[start:end])\n",
      "            start = end\n",
      "        diff_sections.append(patch[start:])\n",
      "\n",
      "        try:\n",
      "            return [Diff(lines) for lines in diff_sections]\n",
      "        except Exception as e:\n",
      "            import traceback\n",
      "\n",
      "            print(f\"Error parsing diff:\\n{e}\")\n",
      "            traceback.print_exc()\n",
      "  repo/repository.py#52.38\n",
      "----------------------------------------------------------------------\n",
      "class GitRepo:\n",
      "\n",
      "    def checkout(self, branch_name: str, new=False):\n",
      "        \"\"\"\n",
      "        Checks out an existing branch in the repo\n",
      "        \"\"\"\n",
      "        if new:\n",
      "            branch = self.repo.create_head(branch_name)\n",
      "        else:\n",
      "            branch = self.repo.heads[branch_name]\n",
      "\n",
      "        print(f\"Checking out: {branch}\")\n",
      "        branch.checkout()\n",
      "\n",
      "    def clean_branches(self, branch_prefix: str):\n",
      "        \"\"\"\n",
      "        Deletes all branches with a specific prefix\n",
      "        \"\"\"\n",
      "        removed = []\n",
      "        for branch in self.repo.branches:\n",
      "            if branch.name.startswith(branch_prefix):\n",
      "                removed.append(branch.name)\n",
      "                self.repo.delete_head(branch)\n",
      "\n",
      "        return removed\n",
      "\n",
      "    @property\n",
      "    def remote_commit(self) -> str:\n",
      "        \"\"\"\n",
      "        Gets the sha of latest commit on origin\n",
      "        \"\"\"\n",
      "        self.repo.remotes.origin.fetch()\n",
      "        remote_sha = self.repo.remotes.origin.refs.__getattr__(self.main).commit.hexsha\n",
      "\n",
      "        return remote_sha\n",
      "\n",
      "    @property\n",
      "    def local_commit(self) -> str:\n",
      "        return self.repo.head.commit.hexsha\n",
      "\n",
      "    # TODO: move this into sync_repo\n",
      "  repo/repository.py#53.30\n",
      "----------------------------------------------------------------------\n",
      "class GitRepo:\n",
      "    def fetch_diffs(self) -> Tuple[CommitDiff, str]:\n",
      "        \"\"\"\n",
      "        Diffs the remote with our local repo\n",
      "        \"\"\"\n",
      "        try:\n",
      "            if self.local_commit == self.remote_commit:\n",
      "                print(\"No updates available.\")\n",
      "                return None, None\n",
      "            else:\n",
      "                print(\"Updates found!\")\n",
      "\n",
      "                # Get the diff between the old commit and the new HEAD\n",
      "                diff = self.repo.git.diff(self.local_commit, self.remote_commit)\n",
      "                commit_diff = CommitDiff(diff)\n",
      "\n",
      "                return commit_diff, self.remote_commit\n",
      "        except Exception as e:\n",
      "            print(f\"An error occurred: {e}\")\n",
      "            return None\n",
      "\n",
      "    def pull(self):\n",
      "        self.repo.remotes.origin.pull()\n",
      "\n",
      "    def add_n_commit(self, files: List[str], msg: str):\n",
      "        self.repo.index.add(files)\n",
      "        self.repo.index.commit(msg)\n",
      "\n",
      "    def push(self, branch_name: str = \"\", force: bool = False):\n",
      "        if not branch_name:\n",
      "            branch_name = self.main\n",
      "        self.origin.push(refspec=f\"{branch_name}:{branch_name}\", force=True)\n"
     ]
    }
   ],
   "source": [
    "all_nodes = []\n",
    "\n",
    "for cluster, nodes in list(cluster2node.items())[:10]:\n",
    "    all_nodes.extend([node.id for node in nodes])\n",
    "    print(f\"Cluster {cluster}\")\n",
    "    for node in nodes:\n",
    "        print(f\"  {node}\")\n",
    "        print(\"----------------------------------------------------------------------\")\n",
    "        print(node.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"cowboy/cli.py#18.36\": 0,\n",
      "  \"db/core.py#20.151\": 0,\n",
      "  \"http/base.py#28.19\": 0,\n",
      "  \"repo/repo.py#37.29\": 0,\n",
      "  \"runner/python.py#47.17\": 0,\n",
      "  \"C:\\\\Users\\\\jpeng\\\\Documents\\\\projects\\\\cowboy_baseline\\\\tests\\\\repos\\\\cowboy\\\\cowboy\\\\exceptions.py__\": 0,\n",
      "  \"cowboy/cli.py#13.53\": 1,\n",
      "  \"runner/python.py#45.40\": 1,\n",
      "  \"task_client/client.py#54.20\": 1,\n",
      "  \"C:\\\\Users\\\\jpeng\\\\Documents\\\\projects\\\\cowboy_baseline\\\\tests\\\\repos\\\\cowboy\\\\cowboy\\\\repo\\\\models.py_RepoConfig.validate_url_RepoConfig.serialize.return._\": 1,\n",
      "  \"C:\\\\Users\\\\jpeng\\\\Documents\\\\projects\\\\cowboy_baseline\\\\tests\\\\repos\\\\cowboy\\\\cowboy\\\\repo\\\\repo.py_create_cloned_folders_create_cloned_folders.return.cloned_folders\": 1,\n",
      "  \"http/base.py#25.36\": 2,\n",
      "  \"http/check_release.py#29.23\": 2,\n",
      "  \"repo/models.py#34.28\": 2,\n",
      "  \"repo/repo.py#36.26\": 2,\n",
      "  \"C:\\\\Users\\\\jpeng\\\\Documents\\\\projects\\\\cowboy_baseline\\\\tests\\\\repos\\\\cowboy\\\\cowboy\\\\db\\\\core.py_json_\": 2,\n",
      "  \"cowboy/browser.py#9.18\": 3,\n",
      "  \"http/base.py#27.23\": 3,\n",
      "  \"repo/repo.py#38.22\": 3,\n",
      "  \"C:\\\\Users\\\\jpeng\\\\Documents\\\\projects\\\\cowboy_baseline\\\\tests\\\\repos\\\\cowboy\\\\cowboy\\\\utils.py_random_\": 3,\n",
      "  \"cowboy/cli.py#15.32\": 4,\n",
      "  \"cowboy/cli.py#17.19\": 4,\n",
      "  \"C:\\\\Users\\\\jpeng\\\\Documents\\\\projects\\\\cowboy_baseline\\\\tests\\\\repos\\\\cowboy\\\\cowboy\\\\browser.py_serve_ui_\": 4,\n",
      "  \"cowboy/cli.py#11.35\": 5,\n",
      "  \"C:\\\\Users\\\\jpeng\\\\Documents\\\\projects\\\\cowboy_baseline\\\\tests\\\\repos\\\\cowboy\\\\cowboy\\\\db\\\\public.py__\": 5,\n",
      "  \"api_cmds/__init__.py#1.6\": 6,\n",
      "  \"api_cmds/augment.py#2.37\": 7,\n",
      "  \"api_cmds/build_mapping.py#3.24\": 8,\n",
      "  \"api_cmds/experiment.py#4.30\": 9,\n",
      "  \"api_cmds/get_tms.py#5.14\": 10,\n",
      "  \"api_cmds/register.py#6.10\": 11,\n",
      "  \"api_cmds/remote_head.py#7.15\": 12,\n",
      "  \"cowboy/browser.py#8.26\": 13,\n",
      "  \"cowboy/cli.py#10.55\": 14,\n",
      "  \"cowboy/cli.py#12.24\": 15,\n",
      "  \"cowboy/cli.py#14.24\": 16,\n",
      "  \"cowboy/cli.py#16.19\": 17,\n",
      "  \"cowboy/config.py#19.36\": 18,\n",
      "  \"db/public.py#21.16\": 19,\n",
      "  \"cowboy/exceptions.py#22.10\": 20,\n",
      "  \"http/__init__.py#23.2\": 21,\n",
      "  \"http/base.py#24.32\": 22,\n",
      "  \"http/base.py#26.25\": 23,\n",
      "  \"http/check_release.py#30.31\": 24,\n",
      "  \"cowboy/logger.py#31.40\": 25,\n",
      "  \"repo/models.py#32.33\": 26,\n",
      "  \"repo/models.py#33.26\": 27,\n",
      "  \"repo/repo.py#35.37\": 28,\n",
      "  \"runner/__init__.py#39.4\": 29,\n",
      "  \"runner/base.py#40.43\": 30,\n",
      "  \"runner/base.py#41.34\": 31,\n",
      "  \"runner/python.py#42.37\": 32,\n",
      "  \"runner/python.py#43.19\": 33,\n",
      "  \"runner/python.py#44.50\": 34,\n",
      "  \"runner/python.py#46.23\": 35,\n",
      "  \"runner/python.py#48.34\": 36,\n",
      "  \"runner/python.py#49.31\": 37,\n",
      "  \"runner/python.py#50.52\": 38,\n",
      "  \"runner/python.py#51.51\": 39,\n",
      "  \"task_client/__init__.py#52.1\": 40,\n",
      "  \"task_client/client.py#53.62\": 41,\n",
      "  \"task_client/client.py#55.40\": 42,\n",
      "  \"task_client/client.py#56.21\": 43,\n",
      "  \"task_client/client.py#57.19\": 44,\n",
      "  \"task_client/client.py#58.33\": 45,\n",
      "  \"task_client/manager.py#59.71\": 46,\n",
      "  \"cowboy/utils.py#60.54\": 47,\n",
      "  \"scripts/revert_config_debug.py#61.16\": 48,\n",
      "  \"cowboy/setup.py#62.32\": 49,\n",
      "  \"tests/find_race_cond.py#63.37\": 50,\n",
      "  \"tests/stress.py#64.47\": 51\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 6,\n",
       "         1: 5,\n",
       "         2: 5,\n",
       "         3: 4,\n",
       "         4: 3,\n",
       "         5: 2,\n",
       "         6: 1,\n",
       "         7: 1,\n",
       "         8: 1,\n",
       "         9: 1,\n",
       "         10: 1,\n",
       "         11: 1,\n",
       "         12: 1,\n",
       "         13: 1,\n",
       "         14: 1,\n",
       "         15: 1,\n",
       "         16: 1,\n",
       "         17: 1,\n",
       "         18: 1,\n",
       "         19: 1,\n",
       "         20: 1,\n",
       "         21: 1,\n",
       "         22: 1,\n",
       "         23: 1,\n",
       "         24: 1,\n",
       "         25: 1,\n",
       "         26: 1,\n",
       "         27: 1,\n",
       "         28: 1,\n",
       "         29: 1,\n",
       "         30: 1,\n",
       "         31: 1,\n",
       "         32: 1,\n",
       "         33: 1,\n",
       "         34: 1,\n",
       "         35: 1,\n",
       "         36: 1,\n",
       "         37: 1,\n",
       "         38: 1,\n",
       "         39: 1,\n",
       "         40: 1,\n",
       "         41: 1,\n",
       "         42: 1,\n",
       "         43: 1,\n",
       "         44: 1,\n",
       "         45: 1,\n",
       "         46: 1,\n",
       "         47: 1,\n",
       "         48: 1,\n",
       "         49: 1,\n",
       "         50: 1,\n",
       "         51: 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "print(json.dumps(chunk2cluster, indent=2))\n",
    "\n",
    "Counter([x for x in chunk2cluster.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
